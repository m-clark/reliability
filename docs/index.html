<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="radix" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>reliability: The Uncertainty of Reliability</title>
  
  <meta property="description" itemprop="description" content="Notions of consistency"/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2019-01-08"/>
  <meta property="article:created" itemprop="dateCreated" content="2019-01-08"/>
  <meta name="article:author" content="Michael Clark"/>
  <meta name="article:author" content="Xilin Chen"/>
  <meta name="article:author" content="Seth Berry"/>
  <meta name="article:author" content="Josh Errickson"/>
  <meta name="article:author" content="Richard Herrington"/>
  <meta name="article:author" content="Brian C. George"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="reliability: The Uncertainty of Reliability"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Notions of consistency"/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:site_name" content="reliability"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="reliability: The Uncertainty of Reliability"/>
  <meta property="twitter:description" content="Notions of consistency"/>
  
  <!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
  <meta name="citation_title" content="reliability: The Uncertainty of Reliability"/>
  <meta name="citation_fulltext_html_url" content="https://m-clark.github.io/reliability"/>
  <meta name="citation_online_date" content="2019/01/08"/>
  <meta name="citation_publication_date" content="2019/01/08"/>
  <meta name="citation_author" content="Michael Clark"/>
  <meta name="citation_author_institution" content="University of Michigan, CSCAR"/>
  <meta name="citation_author" content="Xilin Chen"/>
  <meta name="citation_author_institution" content="University of Michigan, C-STAR"/>
  <meta name="citation_author" content="Seth Berry"/>
  <meta name="citation_author_institution" content="University of Notre Dame, Mendoza"/>
  <meta name="citation_author" content="Josh Errickson"/>
  <meta name="citation_author_institution" content="University of Michigan, CSCAR"/>
  <meta name="citation_author" content="Richard Herrington"/>
  <meta name="citation_author_institution" content="University of North Texas, DSA"/>
  <meta name="citation_author" content="Brian C. George"/>
  <meta name="citation_author_institution" content="University of Michigan, PLSC"/>
  <!--/radix_placeholder_meta_tags-->
  
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","bibliography","output","repository_url","citation_url"]}},"value":[{"type":"character","attributes":{},"value":["The Uncertainty of Reliability"]},{"type":"character","attributes":{},"value":["Notions of consistency\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Michael Clark"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io"]},{"type":"character","attributes":{},"value":["University of Michigan, CSCAR"]},{"type":"character","attributes":{},"value":["https://cscar.research.umich.edu/"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Xilin Chen"]},{"type":"character","attributes":{},"value":["https://www.procedurallearning.org/"]},{"type":"character","attributes":{},"value":["University of Michigan, C-STAR"]},{"type":"character","attributes":{},"value":["https://www.procedurallearning.org/"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Seth Berry"]},{"type":"character","attributes":{},"value":["https://mendoza.nd.edu/research-and-faculty/directory/seth-berry/"]},{"type":"character","attributes":{},"value":["University of Notre Dame, Mendoza"]},{"type":"character","attributes":{},"value":["https://mendoza.nd.edu/"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Josh Errickson"]},{"type":"character","attributes":{},"value":["https://errickson.net/"]},{"type":"character","attributes":{},"value":["University of Michigan, CSCAR"]},{"type":"character","attributes":{},"value":["https://cscar.research.umich.edu/"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Richard Herrington"]},{"type":"character","attributes":{},"value":["https://errickson.net/"]},{"type":"character","attributes":{},"value":["University of North Texas, DSA"]},{"type":"character","attributes":{},"value":["https://it.unt.edu/research/"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Brian C. George"]},{"type":"character","attributes":{},"value":["https://www.procedurallearning.org/"]},{"type":"character","attributes":{},"value":["University of Michigan, PLSC"]},{"type":"character","attributes":{},"value":["https://www.procedurallearning.org/"]}]}]},{"type":"character","attributes":{},"value":["2019-01-08"]},{"type":"character","attributes":{},"value":["measurement.bib"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["radix::radix_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["css","toc"]}},"value":[{"type":"character","attributes":{},"value":["radix.css"]},{"type":"logical","attributes":{},"value":[true]}]}]},{"type":"character","attributes":{},"value":["https://github.com/m-clark/reliability"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io/reliability"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  d-code {
    overflow-x: auto !important;
  }
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  
  d-code {
    overflow-x: visible !important;
  }
  
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.radix-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
  <script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->

  <link rel="stylesheet" href="radix.css" type="text/css"/>

</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"The Uncertainty of Reliability","description":"Notions of consistency","authors":[{"author":"Michael Clark","authorURL":"https://m-clark.github.io","affiliation":"University of Michigan, CSCAR","affiliationURL":"https://cscar.research.umich.edu/"},{"author":"Xilin Chen","authorURL":"https://www.procedurallearning.org/","affiliation":"University of Michigan, C-STAR","affiliationURL":"https://www.procedurallearning.org/"},{"author":"Seth Berry","authorURL":"https://mendoza.nd.edu/research-and-faculty/directory/seth-berry/","affiliation":"University of Notre Dame, Mendoza","affiliationURL":"https://mendoza.nd.edu/"},{"author":"Josh Errickson","authorURL":"https://errickson.net/","affiliation":"University of Michigan, CSCAR","affiliationURL":"https://cscar.research.umich.edu/"},{"author":"Richard Herrington","authorURL":"https://errickson.net/","affiliation":"University of North Texas, DSA","affiliationURL":"https://it.unt.edu/research/"},{"author":"Brian C. George","authorURL":"https://www.procedurallearning.org/","affiliation":"University of Michigan, PLSC","affiliationURL":"https://www.procedurallearning.org/"}],"publishedDate":"2019-01-08T00:00:00.000-05:00","citationText":"Clark, et al., 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>The Uncertainty of Reliability</h1>
<p>Notions of consistency</p>
</div>

<div class="d-byline">
  Michael Clark <a href="https://m-clark.github.io" class="uri">https://m-clark.github.io</a> (University of Michigan, CSCAR)<a href="https://cscar.research.umich.edu/" class="uri">https://cscar.research.umich.edu/</a>
  
,   Xilin Chen <a href="https://www.procedurallearning.org/" class="uri">https://www.procedurallearning.org/</a> (University of Michigan, C-STAR)<a href="https://www.procedurallearning.org/" class="uri">https://www.procedurallearning.org/</a>
  
,   Seth Berry <a href="https://mendoza.nd.edu/research-and-faculty/directory/seth-berry/" class="uri">https://mendoza.nd.edu/research-and-faculty/directory/seth-berry/</a> (University of Notre Dame, Mendoza)<a href="https://mendoza.nd.edu/" class="uri">https://mendoza.nd.edu/</a>
  
,   Josh Errickson <a href="https://errickson.net/" class="uri">https://errickson.net/</a> (University of Michigan, CSCAR)<a href="https://cscar.research.umich.edu/" class="uri">https://cscar.research.umich.edu/</a>
  
,   Richard Herrington <a href="https://errickson.net/" class="uri">https://errickson.net/</a> (University of North Texas, DSA)<a href="https://it.unt.edu/research/" class="uri">https://it.unt.edu/research/</a>
  
,   Brian C. George <a href="https://www.procedurallearning.org/" class="uri">https://www.procedurallearning.org/</a> (University of Michigan, PLSC)<a href="https://www.procedurallearning.org/" class="uri">https://www.procedurallearning.org/</a>
  
<br/>2019-01-08
</div>

<div class="d-article">
<h3 class="d-toc-header">Table of Contents</h3>
<nav class="d-toc" id="TOC">
<ul>
<li><a href="#the-meaning-of-reliability">The Meaning of Reliability</a><ul>
<li><a href="#what-we-talk-about-when-we-talk-about-reliability">What we talk about when we talk about reliability</a></li>
</ul></li>
<li><a href="#statistical-reliability">Statistical Reliability</a><ul>
<li><a href="#classical-test-theory">Classical Test Theory</a></li>
<li><a href="#correlation">Correlation</a></li>
<li><a href="#consistency">Consistency</a></li>
<li><a href="#measurement-of-a-construct">Measurement of a Construct</a></li>
<li><a href="#the-psychometric-definition-of-reliability">The psychometric definition of reliability</a></li>
</ul></li>
<li><a href="#demonstrations">Demonstrations</a><ul>
<li><a href="#preliminaries">Preliminaries</a></li>
<li><a href="#coefficient-alpha">Coefficient <span class="math inline">\(\alpha\)</span></a></li>
</ul></li>
<li><a href="#section"></a><ul>
<li><a href="#generalizability-theory">Generalizability theory</a></li>
<li><a href="#factor-analysis">Factor Analysis</a></li>
<li><a href="#conclusion-and-summary">Conclusion and Summary</a></li>
<li><a href="#appendix">Appendix</a></li>
<li><a href="#acknowledgments">Acknowledgments</a></li>
<li><a href="#author-contributions">Author Contributions</a></li>
</ul></li>
</ul>
</nav>
<hr class="d-toc-separator"/>
<p><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.3/css/all.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous"></p>
<h4 id="goalsabstract">Goals/Abstract</h4>
<p>To examine reliability from different perspectives, and the uncertainty in the measurement of it.</p>
<h4 id="audience">Audience</h4>
<p>Applied practitioners of statistics in fields where the reporting of reliability of measurement is commonplace (e.g. psychology, education, biomedical sciences). Supplemental material may go deeper and be of interest to methodologists.</p>
<h2 id="the-meaning-of-reliability">The Meaning of Reliability</h2>
<h3 id="what-we-talk-about-when-we-talk-about-reliability">What we talk about when we talk about reliability</h3>
<p>When used in everyday discourse, no one really wonders what we mean when we say something is <span class="emph">reliable</span>. If you are talking about a car and you say it’s reliable, it means it won’t break down on you. If we talk about a person being reliable, it means we can depend on them to provide consistent behavior, e.g. regarding a specific task. Reliable electric service means one can keep the lights on all day. This everyday notion of reliability is closely related to the notion of dependability as well. We can depend on the person, car, or whatever, to do what we <em>expect</em>. Even though we may agree on this concept of reliability, pause should be taken. A reliable car from the 1970s would not meet acceptable standards for reliability these days. Your assessment and standard of reliablity may be wholly different if talking about a brother or sister. Thus, some fuzziness is inherent even with the everyday notion of reliability.</p>
<p>While we can talk about reliability from an everyday standpoint, the concept has been carried over to the realm of scientific analysis of data as well. And while the concept may be applied, it must of course become more precise, as scientific endeavor dictates. It may surprise some that reliability has been studied scientifically for over a century. With that knowledge however, it should not be too surprising that numerous statistical techniques have been advanced over that time, and the varieties will often align with different notions of reliability.</p>
<aside>
Charles Spearman (1904) examined the attenuation of correlation due to measurement error, but there were still earlier investigations. See Revelle chapter 7 for a brief history<span class="citation" data-cites="revelle_introduction_nodate">(Revelle <a href="#ref-revelle_introduction_nodate">n.d.</a>)</span>.
</aside>
<p>Even when positing a specific statistic for reliability, our investigation should not end there. As with the everyday notion of reliablity, there is <span class="emph">uncertainty</span> in the scientific measurement of it, and we should have some grasp of the nature of that uncertainty, else we risk becoming overly confident in our understanding of a measure. Thus what holds for other statistical measures - means, regression coefficients, and so on - will apply to any measurment of reliability as well.</p>
<p>In what follows we seek to trace out a few of the definitions of reliability associated with some of the more common statistical measures of it. Classical test theory will lay the foundation, after which we will explore an understanding of reliability from simple correlations, to the concept of consistency, and finally toward thinking about latent constructs and measurement error more deeply. Demonstrations of each notion of reliability will then be provided, not focused on merely producing a statistic, but establishing the uncertainty surrounding it, and understanding it with that context. General comparisons and contrasts about the different approaches will be made, and suggestions about practical ways to proceed offered. And finally, much more advance and technical exploration will be undertaken in the supplemental addendum to this document.</p>
<h2 id="statistical-reliability">Statistical Reliability</h2>
<h3 id="classical-test-theory">Classical Test Theory</h3>
<p>The foundation for understanding reliability from a statistical standpoint resides with <span class="emph">Classical Test Theory</span>. The title may be offputting at first blush, but it is conceptually straightforward. Even then, as McDonald <span class="citation" data-cites="mcdonald_test_1999">McDonald (<a href="#ref-mcdonald_test_1999">1999</a>)</span> put it-</p>
<blockquote>
<p>The mathematics of the theory is extremely simple. The application of the theory can be problematic.</p>
</blockquote>
<p>So what are the mathematics? Simple arithmetic.</p>
<p><span class="math display">\[\mathrm{Observed\  Score = True\  Score + Error}\]</span></p>
<p>But what does this mean? Any measurement we take of something provides us an observed score. For example, we step on a scale and note our weight. A perfect measurement would provide the right score every time, and thus our observed score would equal the <span class="emph">true score</span>. But no measurement is perfect<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, i.e. everything is measured with some amount of <span class="emph">error</span>, however small. The error can be random, variability caused by unknown sources, but which will not affect our average account of a thing. Our weight from the scale goes up and down but on average it is correct. Error can also be systematic, where the measurement is always off by some amount, and our observed score is always too high or too low. In this scenario, our scale may always be displaying a greater weight than it should. Unfortunately, it is very difficult, if not impossible, to distinguish the two in many typical circumstances.</p>
<aside>
Note that by <span class="emph">test</span>, we mean any thing we might want to measure. The study of measurement was, after (psycho-)physics, largely dominated by education and psychology for decades, but needn’t be restricted to those domains.
</aside>
<p>So conceptually we can simply think of an observation of any measure being composed of whatever the true score would be plus some associated error. The key idea is that the assessment of the error will allow us to understand how reliable our measure is.</p>
<h3 id="correlation">Correlation</h3>
<p>Let’s start with correlation. If two things are correlated, they move in tandem, either they go up and down together, or as one goes up the other goes down and vice versa. At the very least of our understanding of reliability is that similar measurements of the same thing should be correlated. But this correlation might be assessed by different means.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="index_files/figure-html5/corplot-1.svg" width="624" /></p>
</div>
<h4 id="test-retest">Test-retest</h4>
<div style="text-align: center; size=200%">
<p><i class="fas fa-file-alt fa-9x" style="color: #ff550095"></i> <i class="fas fa-file-alt fa-9x" style="color: #ff550095; border-style: solid; border-width: 1px; border-color: #ffffff; margin-left: -50px"></i> <i class="fas fa-file-alt fa-9x" style="color: #ff550095; border-style: solid; border-width: 1px; border-color: #ffffff; margin-left: -50px"></i></p>
</div>
<p>Let’s say we now take the weights of one hundred people. Then we do so again six months later. We should expect that heavier people at the first measurement will likely be heavier the second time as well. Same for lighter people.</p>
<p>That correlation of the two measurments can provide us our first attempt at measuring reliability. Typically referred to as test-retest reliability, this notion gives us some understanding of the stability or consistency of measurement <em>across time</em>. While this is useful and straightforward, many situations will not allow for multiple testing occasions, so we’ll need other alternatives.</p>
<h4 id="parallel-forms">Parallel Forms</h4>
<div style="text-align: center; ">
<p><i class="fas fa-file-alt fa-9x" style="color: #ff5500BF "> </i> <span style=" display:inline-block; width:25px"></span> <i class="fas fa-file-alt fa-9x" style="color: #ff550080"></i> <span style=" display:inline-block; width:25px"></span> <i class="fas fa-file-alt fa-9x" style="color: #ff550040"></i></p>
</div>
<p>One method instructors used to use to thwart cheating was to provide half of the class one version of the test, and the other half a different version, that covered the same content, but which had slightly different questions/answers. When passed out randomly, students couldn’t peek at their neighbor’s test and gain any advantage. In terms of classical test theory, if we gave these parallel/alternate forms to each student, the true score for any student would be the same, regardless of what form they took, and any observed score differences would be error.</p>
<p>In the more common applied research setting, the question then is how do we know if we are dealing with parallel tests? Unless they are derived as such, we cannot say for certain, and this usually only happens in educational settings, such as with the SAT or GRE. Beyond that it is probably rare that resources allow for parallel forms of measurement, or if they do, enough forms to test the assumption of parallelism.</p>
<h4 id="split-half">Split-half</h4>
<div style="text-align: center; size=200%">
<p><img src="img/split_half.svg" style="display:block; margin: 0 auto; height: 9em; opacity: .75"></p>
</div>
<p>A notion of reliability not too far removed from the previous is that of split-half reliability. If our measure is made up of multiple observations, say, survey questions, scale items, or whatever, we can just take a random half of them, get a total score for each individual, and do the same with the other half. Now each person has two scores, and their correlation gives us a glimpse of the reliability of the measure. Consider it a poor man’s alternate forms approach.</p>
<h3 id="consistency">Consistency</h3>
<p>Split-half reliability allows us to estimate reliability with only one test. This is important, as many times we can only measure something in one setting, even if multiple times within that setting. For example, there may be only one qualifying exam, one survey administered, and so forth. As such we need some way to assess the <span class="emph">internal structure</span> of the measure. Some of the most commonly used statistics, such as coefficient <span class="math inline">\(\alpha\)</span>, offer such a measure. For that, it will still be based on simple correlations, but as we don’t have multiple tests, the correlations will regard the items or instances of the measure we have from the setting observations occur. The average correlation across all items will serve as the basis for an assessment of reliability, but the number of items will have a say as well.</p>
<h3 id="measurement-of-a-construct">Measurement of a Construct</h3>
<p>Finally, we can think about reliability in terms of how well the tests measure the construct. Some would call this validity, though the distinction is muddier in practice. The observed measurements we have are imperfect measurements of the thing they are purported to measure. Estimation of that imperfection is the whole of reliability analysis. We can get at this notion more intently with tools from <span class="emph">factor analysis</span>, and can begin to think about reliability in terms of how much of the <em>latent</em> constuct is actually in the observed measures.</p>
<h3 id="the-psychometric-definition-of-reliability">The psychometric definition of reliability</h3>
<p>We can summarize all of the previous by returning to the classical test theory notion of reliability. In general, the reliability of a measure <span class="math inline">\(\rho\)</span> is the proportion of true score variance to the total observed variance.</p>
<p><span class="math display">\[\rho = \frac{\sigma^2_T}{\sigma^2_T + \sigma^2_e}\]</span></p>
<h2 id="demonstrations">Demonstrations</h2>
<h3 id="preliminaries">Preliminaries</h3>
<p>Before diving into demonstration we will first describe the data and analytical approach. Both observed and simulated data will be presented, followed by discussion of the analysis.</p>
<h4 id="data-description">Data Description</h4>
<h5 id="observed-data">Observed Data</h5>
<p>The Big Five Inventory is a popular personality scale use in a wide variety of applications. For our example, we will have at our disposal 25 items corresponding to the five subscales- Agreeableness, Openness, Extroversion, Conscientiousness, and Neuroticism. However, we will concern ourselves with the Neurtocism subscale specifically. This particular data is available in the R package <span class="pack">psych</span>, and regards 2800 subjects as part of the Synthetic Aperture Personality Assessment (SAPA) web based personality assessment project. The items are six-point scales ranging from 1 Very Inaccurate to six 6 Very Accurate, and are statements that may reflect the person’s assessment of themselves. The neuroticism items in particular are:</p>
<ul>
<li>N1: Get angry easily.</li>
<li>N2: Get irritated easily.</li>
<li>N3: Have frequent mood swings.</li>
<li>N4: Often feel blue.</li>
<li>N5: Panic easily.</li>
</ul>
<p>More details can be found with the data object’s (<span class="objclass">bfi</span>) associated helpfile. The following shows how the data may be obtained. To make comparisons across the different approaches more easily comparable, I go ahead and remove the rows with missing data.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(tidyverse)
library(psych)
neuroticism = bfi %&gt;% 
  select(N1:N5) %&gt;% 
  drop_na()</code></pre>
</div>
<p>Basic descriptives and correlations are shown next. While there is some missing data, some reliability statistics will be based on pairwise correlations, and thus use all available information. Some of the item correlations are not that strong, but this is a realistic situation for many data in social and related sciences.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:right;">
N
</th>
<th style="text-align:right;">
Mean
</th>
<th style="text-align:right;">
SD
</th>
<th style="text-align:right;">
Median
</th>
<th style="text-align:right;">
Missing
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
N1
</td>
<td style="text-align:right;">
2694
</td>
<td style="text-align:right;">
2.93
</td>
<td style="text-align:right;">
1.57
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
N2
</td>
<td style="text-align:right;">
2694
</td>
<td style="text-align:right;">
3.51
</td>
<td style="text-align:right;">
1.53
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
N3
</td>
<td style="text-align:right;">
2694
</td>
<td style="text-align:right;">
3.22
</td>
<td style="text-align:right;">
1.60
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
N4
</td>
<td style="text-align:right;">
2694
</td>
<td style="text-align:right;">
3.19
</td>
<td style="text-align:right;">
1.57
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
N5
</td>
<td style="text-align:right;">
2694
</td>
<td style="text-align:right;">
2.97
</td>
<td style="text-align:right;">
1.62
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
N1
</th>
<th style="text-align:right;">
N2
</th>
<th style="text-align:right;">
N3
</th>
<th style="text-align:right;">
N4
</th>
<th style="text-align:right;">
N5
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
N1
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.71
</td>
<td style="text-align:right;">
0.56
</td>
<td style="text-align:right;">
0.40
</td>
<td style="text-align:right;">
0.38
</td>
</tr>
<tr>
<td style="text-align:left;">
N2
</td>
<td style="text-align:right;">
0.71
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.55
</td>
<td style="text-align:right;">
0.39
</td>
<td style="text-align:right;">
0.35
</td>
</tr>
<tr>
<td style="text-align:left;">
N3
</td>
<td style="text-align:right;">
0.56
</td>
<td style="text-align:right;">
0.55
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.52
</td>
<td style="text-align:right;">
0.43
</td>
</tr>
<tr>
<td style="text-align:left;">
N4
</td>
<td style="text-align:right;">
0.40
</td>
<td style="text-align:right;">
0.39
</td>
<td style="text-align:right;">
0.52
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.40
</td>
</tr>
<tr>
<td style="text-align:left;">
N5
</td>
<td style="text-align:right;">
0.38
</td>
<td style="text-align:right;">
0.35
</td>
<td style="text-align:right;">
0.43
</td>
<td style="text-align:right;">
0.40
</td>
<td style="text-align:right;">
1.00
</td>
</tr>
</tbody>
</table>
</div>
<h5 id="simulatedideal-data">Simulated/Ideal data</h5>
<p>One of our investigations into reliability will involve what is commonly referred to as factor analysis. Along with the observed data just described, the <span class="pack">psych</span> package additionally provides an easy means to simulate data with known factor structure. We can specify the number of factors, loadings, number of items among other things. Doing so will allow us to know what to expect from the factor analysis portion of the exploration, and explore uni- vs. multidimensional structure if desired. As a starting point, we will simulate a <span class="emph">congeneric</span> data set, one in which the factor structure regards just one latent variable underlying the items. We will have six items for this data, with moderate to strong loadings between .4 and .7.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
set.seed(123)
N = 1000
n_items = 6
loadings_congeneric = c(.4, .4, .5, .5, .6, .7)

cor_congeneric = sim.congeneric(loadings_congeneric, N = N)

data_congeneric = 
  mvtnorm::rmvnorm(n = N, 
                   mean = rep(0, n_items), 
                   sigma = cor_congeneric) %&gt;% 
  as_data_frame() %&gt;% 
  rename_all(str_replace, pattern = &#39;V&#39;, replacement = &#39;item_&#39;)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
item_1
</th>
<th style="text-align:right;">
item_2
</th>
<th style="text-align:right;">
item_3
</th>
<th style="text-align:right;">
item_4
</th>
<th style="text-align:right;">
item_5
</th>
<th style="text-align:right;">
item_6
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
-1.158
</td>
<td style="text-align:right;">
0.592
</td>
<td style="text-align:right;">
2.019
</td>
<td style="text-align:right;">
0.797
</td>
<td style="text-align:right;">
1.869
</td>
<td style="text-align:right;">
0.329
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.038
</td>
<td style="text-align:right;">
1.193
</td>
<td style="text-align:right;">
0.635
</td>
<td style="text-align:right;">
0.845
</td>
<td style="text-align:right;">
0.108
</td>
<td style="text-align:right;">
0.213
</td>
</tr>
<tr>
<td style="text-align:right;">
0.398
</td>
<td style="text-align:right;">
0.211
</td>
<td style="text-align:right;">
0.828
</td>
<td style="text-align:right;">
-0.138
</td>
<td style="text-align:right;">
-0.534
</td>
<td style="text-align:right;">
1.333
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.712
</td>
<td style="text-align:right;">
0.194
</td>
<td style="text-align:right;">
-1.546
</td>
<td style="text-align:right;">
-0.551
</td>
<td style="text-align:right;">
1.944
</td>
<td style="text-align:right;">
0.084
</td>
</tr>
<tr>
<td style="text-align:right;">
0.839
</td>
<td style="text-align:right;">
0.521
</td>
<td style="text-align:right;">
-1.203
</td>
<td style="text-align:right;">
0.798
</td>
<td style="text-align:right;">
-0.822
</td>
<td style="text-align:right;">
0.606
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.098
</td>
<td style="text-align:right;">
-0.047
</td>
<td style="text-align:right;">
0.429
</td>
<td style="text-align:right;">
-0.356
</td>
<td style="text-align:right;">
-0.116
</td>
<td style="text-align:right;">
0.364
</td>
</tr>
</tbody>
</table>
</div>
<h4 id="analytical-approach">Analytical Approach</h4>
<p>The analysis of the data will be conducted on both the observed and simulated data sets. We will show three conceptual estimates of reliability, but, in addition, we will focus on the estimated uncertainty in those estimates. Far too often reliability statistics are reported without any thought of the underlying models, or that there is possibly notable uncertainty in the estimate. The three conceptual estimates include the most popular estimate of reliability, Coefficient <span class="math inline">\(\alpha\)</span>, followed by two model-based approaches - generalizability theory and latent variable/factor analysis.</p>
<h3 id="coefficient-alpha">Coefficient <span class="math inline">\(\alpha\)</span></h3>
<aside>
Though it was developed independently a few years earlier by Guttman 1945, coefficient <span class="math inline">\(\alpha\)</span> is often called Cronbach’s <span class="math inline">\(\alpha\)</span>. We prefer the more neutral terminology, in keeping with Cronbach’s own wishes (Cronbach Shavelson 2004.
</aside>
<p>Coefficient <span class="math inline">\(\alpha\)</span> is one of the most popular measures of reliability. Sometimes considered a measure of <span class="emph">internal consistency</span>, it is a function of the average covariance/correlation among the observations/items, the total variance of the test, as well as the number of items. It is also interpreted as the average of all possible spit-half reliabilities. While it is descriptive in nature, it actually assumes a unidimensional factor structure as the underlying model representation, or in other words, that all the items correspond to the same underlying construct<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>. The standardized formula only requires the two values of the number of items <span class="math inline">\(k\)</span> and average inter-item correlation <span class="math inline">\(\bar{r}\)</span>.</p>
<p><span class="math display">\[\alpha = \frac{k\bar{r}}{1+(k-1)\bar{r}}\]</span></p>
<aside>
The raw score formula for <span class="math inline">\(\alpha\)</span> in terms of the average variance of the items <span class="math inline">\(\bar{v}\)</span> and average covariance <span class="math inline">\(\bar{c}\)</span> is: <span class="math display">\[\alpha = \frac{k\bar{c}}{\bar{v}+(k-1)\bar{c}}\]</span>
</aside>
<p>All else being equal, simply increasing the number of observations/items will give you a higher reliability. In some contexts this may make sense, as the goal is to use an average or sum score, and we are interested in the reliability of that instead of any particular item. In other contexts such an estimate may overestimate the type of reliability we care about.</p>
<p>The following shows the results from the <span class="pack">psych</span> package. In addition to both raw and standardized <span class="math inline">\(\alpha\)</span> measures, it also offers Guttman’s lambda 6, a ‘signal-to-noise’ ratio and tohre info. Shown are the alphas, absolute standard error, and average/median inter-item correlation.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Raw
</th>
<th style="text-align:right;">
Standardized
</th>
<th style="text-align:right;">
Avg. Inter-item cor
</th>
<th style="text-align:right;">
Median r
</th>
<th style="text-align:right;">
ASE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.47
</td>
<td style="text-align:right;">
0.41
</td>
<td style="text-align:right;">
0.01
</td>
</tr>
</tbody>
</table>
</div>
<p>These statistics show how <span class="math inline">\(\alpha\)</span> changes when the item is dropped. We can see that items N1 through N3 are more useful measures, as dropping them would result in a significant drop in <span class="math inline">\(\alpha\)</span>.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
(#tab:cronbach_drop)Reliability if the item is dropped.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Raw
</th>
<th style="text-align:right;">
Standardized
</th>
<th style="text-align:right;">
Avg. Inter-item cor
</th>
<th style="text-align:right;">
Median r
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
N1
</td>
<td style="text-align:right;">
0.76
</td>
<td style="text-align:right;">
0.76
</td>
<td style="text-align:right;">
0.44
</td>
<td style="text-align:right;">
0.41
</td>
</tr>
<tr>
<td style="text-align:left;">
N2
</td>
<td style="text-align:right;">
0.76
</td>
<td style="text-align:right;">
0.76
</td>
<td style="text-align:right;">
0.45
</td>
<td style="text-align:right;">
0.41
</td>
</tr>
<tr>
<td style="text-align:left;">
N3
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.76
</td>
<td style="text-align:right;">
0.44
</td>
<td style="text-align:right;">
0.39
</td>
</tr>
<tr>
<td style="text-align:left;">
N4
</td>
<td style="text-align:right;">
0.79
</td>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
0.49
</td>
<td style="text-align:right;">
0.49
</td>
</tr>
<tr>
<td style="text-align:left;">
N5
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.52
</td>
<td style="text-align:right;">
0.53
</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<h4 id="the-uncertainty-of-alpha">The Uncertainty of <span class="math inline">\(\alpha\)</span></h4>
<p>One issue with Coefficient <span class="math inline">\(\alpha\)</span> is that the uncertainty in the estimate is rarely reported, even though it has been known for some time how to derive a confidence interval for it, and tools are readily available for producing it. The <span class="pack">MBESS</span> package does this in a variety ways. One uses an approach noted in <span class="citation" data-cites="feldt_statistical_1987">Feldt, Woodruff, and Salih (<a href="#ref-feldt_statistical_1987">1987</a>)</span>, and which assumes fixed, rather than random, items and subjects. One is a normal based approximation (see <span class="citation" data-cites="van_zyl_distribution_2000">Zyl, Neudecker, and Nel (<a href="#ref-van_zyl_distribution_2000">2000</a>)</span>). The other method is via the bootstrap (<span class="citation" data-cites="kelley_confidence_2016">Kelley and Pornprasertmanit (<a href="#ref-kelley_confidence_2016">2016</a>)</span>), calculating <span class="math inline">\(\alpha\)</span> for <span class="math inline">\(R\)</span> number of bootstrap resamples of the data. Results are shown below, with the bootstrapped value based on 1000 iterations.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
LL
</th>
<th style="text-align:right;">
alpha
</th>
<th style="text-align:right;">
UL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
boot
</td>
<td style="text-align:right;">
0.8004
</td>
<td style="text-align:right;">
0.8133
</td>
<td style="text-align:right;">
0.8253
</td>
</tr>
<tr>
<td style="text-align:left;">
feldt
</td>
<td style="text-align:right;">
0.8019
</td>
<td style="text-align:right;">
0.8133
</td>
<td style="text-align:right;">
0.8242
</td>
</tr>
<tr>
<td style="text-align:left;">
normal
</td>
<td style="text-align:right;">
0.8021
</td>
<td style="text-align:right;">
0.8133
</td>
<td style="text-align:right;">
0.8245
</td>
</tr>
</tbody>
</table>
</div>
<p>We can see that the bootstrapped interval is essentially the same, but in either case we can see that our estimate of <span class="math inline">\(\alpha\)</span> would best be summarized as some value between .80 and .83.</p>
<h1 id="section"></h1>
<h5 id="a-bayesian-approach">A Bayesian Approach</h5>
<p>An alternative approach to estimating the uncertainty in <span class="math inline">\(\alpha\)</span> would be a Bayesian estimate. We could estimate the value by first estimating the correlation matrix underlying the assumed multivariate normal distribution of the observations/items. Thus the Bayesian <span class="math inline">\(\alpha\)</span> would be based on the posterior predictive distribution given the estimate of the correlation matrix <span class="citation" data-cites="padilla_estimating_2011">Padilla and Zhang (<a href="#ref-padilla_estimating_2011">2011</a>)</span>. Alternatively, we could use a normal approximation for the distribution of the <span class="math inline">\(\alpha\)</span> itself, based on the estimated correlation matrix <span class="citation" data-cites="van_zyl_distribution_2000">(<a href="#ref-van_zyl_distribution_2000">2000</a>)</span>. Yet another approach would be based on a mixed model, calculating an <span class="emph">intra-class correlation coefficent</span> for a set number of items, as in Generalizability theory. We will save that for the following section. More detail can be found in the supplemental materials.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
LL
</th>
<th style="text-align:right;">
alpha
</th>
<th style="text-align:right;">
UL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
normal bayes
</td>
<td style="text-align:right;">
0.789
</td>
<td style="text-align:right;">
0.813
</td>
<td style="text-align:right;">
0.839
</td>
</tr>
<tr>
<td style="text-align:left;">
post. pred.
</td>
<td style="text-align:right;">
0.804
</td>
<td style="text-align:right;">
0.813
</td>
<td style="text-align:right;">
0.822
</td>
</tr>
<tr>
<td style="text-align:left;">
post. pred. non-normal
</td>
<td style="text-align:right;">
0.807
</td>
<td style="text-align:right;">
0.816
</td>
<td style="text-align:right;">
0.824
</td>
</tr>
</tbody>
</table>
</div>
<p>We can also view these estimates directly. The normal approximation is wider than the other two.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="index_files/figure-html5/vis_alpha_bayes-1.svg" width="624" /></p>
</div>
<p>Here are all the estimates of uncertainty calculated. For this amount of data it is not surprising that they are mostly in agreement, though the normal approximation may be a little wider.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
LL
</th>
<th style="text-align:right;">
alpha
</th>
<th style="text-align:right;">
UL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
boot
</td>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.83
</td>
</tr>
<tr>
<td style="text-align:left;">
feldt
</td>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.82
</td>
</tr>
<tr>
<td style="text-align:left;">
normal
</td>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.82
</td>
</tr>
<tr>
<td style="text-align:left;">
normal bayes
</td>
<td style="text-align:right;">
0.79
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.84
</td>
</tr>
<tr>
<td style="text-align:left;">
post. pred.
</td>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.82
</td>
</tr>
<tr>
<td style="text-align:left;">
post. pred. non-normal
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.82
</td>
<td style="text-align:right;">
0.82
</td>
</tr>
</tbody>
</table>
<p><img src="index_files/figure-html5/alpha_all-1.svg" width="624" /></p>
</div>
<h4 id="simulated-data">Simulated Data</h4>
<p>The simulated data allows for us to have a more controlled exploration. We know the items are multivariate normal and unidimensional, so this is where <span class="math inline">\(\alpha\)</span> shines as a measure of reliability. However, one assumption with coefficient <span class="math inline">\(\alpha\)</span> is that the loadings for such a model are equivalent, and we know they aren’t in this case. This will serve as a comparison when we actually look at factor analytic approaches to reliability estimation later. For now, we’ll skip the formality and cut right to the chase. Here are all the previous estimates shown for this data set. The <span class="math inline">\(\alpha\)</span> is lower for this particular data, but in general we’re seeing the same thing.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
LL
</th>
<th style="text-align:right;">
alpha
</th>
<th style="text-align:right;">
UL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
boot
</td>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
0.75
</td>
</tr>
<tr>
<td style="text-align:left;">
feldt
</td>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
0.75
</td>
</tr>
<tr>
<td style="text-align:left;">
normal
</td>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
0.75
</td>
</tr>
<tr>
<td style="text-align:left;">
normal bayes
</td>
<td style="text-align:right;">
0.67
</td>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
0.76
</td>
</tr>
<tr>
<td style="text-align:left;">
post. pred.
</td>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
0.74
</td>
</tr>
<tr>
<td style="text-align:left;">
post. pred. non-normal
</td>
<td style="text-align:right;">
0.71
</td>
<td style="text-align:right;">
0.73
</td>
<td style="text-align:right;">
0.75
</td>
</tr>
</tbody>
</table>
<p><img src="index_files/figure-html5/alpha_compare_congeneric-1.svg" width="624" /></p>
</div>
<h4 id="comparison-to-small-sample">Comparison to small sample</h4>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Size
</th>
<th style="text-align:right;">
LL
</th>
<th style="text-align:right;">
alpha
</th>
<th style="text-align:right;">
UL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
10%
</td>
<td style="text-align:right;">
0.816
</td>
<td style="text-align:right;">
0.848
</td>
<td style="text-align:right;">
0.874
</td>
</tr>
<tr>
<td style="text-align:left;">
5%
</td>
<td style="text-align:right;">
0.793
</td>
<td style="text-align:right;">
0.841
</td>
<td style="text-align:right;">
0.878
</td>
</tr>
</tbody>
</table>
</div>
<h4 id="multidimensional-scale">Multidimensional Scale</h4>
<p>Notes: can’t generalize from subscale to whole or vice versa, alpha &lt; reliability in this setting <span class="citation" data-cites="zinbarg_cronbachs_2005">Zinbarg et al. (<a href="#ref-zinbarg_cronbachs_2005">2005</a>)</span></p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Raw
</th>
<th style="text-align:right;">
Standardized
</th>
<th style="text-align:right;">
Avg. Inter-item cor
</th>
<th style="text-align:right;">
Median r
</th>
<th style="text-align:right;">
ASE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
0.71
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
0.01
</td>
</tr>
</tbody>
</table>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Scale
</th>
<th style="text-align:right;">
Alpha
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Neuro
</td>
<td style="text-align:right;">
0.813
</td>
</tr>
<tr>
<td style="text-align:left;">
Extra
</td>
<td style="text-align:right;">
0.762
</td>
</tr>
<tr>
<td style="text-align:left;">
Open
</td>
<td style="text-align:right;">
0.600
</td>
</tr>
<tr>
<td style="text-align:left;">
Agree
</td>
<td style="text-align:right;">
0.703
</td>
</tr>
<tr>
<td style="text-align:left;">
Consc
</td>
<td style="text-align:right;">
0.727
</td>
</tr>
</tbody>
</table>
</div>
<h4 id="limitations-of-coefficient-alpha">Limitations of Coefficient <span class="math inline">\(\alpha\)</span></h4>
<p>lower bound estimate</p>
<p>assumes single factor and equal loadings for items</p>
<p>merely adding items will improve</p>
<h3 id="generalizability-theory">Generalizability theory</h3>
<p>So called ‘mixed effects’ models are statistical models applicable to situations in which there is some dependency among observations in the data, where that correlation typically arises from the observations being clustered in some way. For example, it is quite common to have data in which we have repeated measurements of individuals, or cases in which the units of observation are otherwise grouped together (e.g. students within school, cities within geographic region). This clustering can be hierarchical in nature (e.g. students within schools, within districts) or not (e.g. students and items on a test). While there are different ways to approach such a situation, mixed models are a powerful tool with which to do so.</p>
<p>Mixed models estimate the variance attributable to various sources of dependency in the data. Thus, aside from the usual regression output, we get a sense of variability due to individuals, schools, surgical procedure or whatever our grouping structure is. In addition, we may estimate cluster-specific effects, which allow for increased predictive capability. Thus we may know the general trend across all individuals, but we can also allow each individual to have separate starting points and trends. These effects</p>
<p><span class="emph">Generalizability Theory</span> focuses on the variance.</p>
<p><span class="math display">\[\rho = \frac{\sigma_g^2}{\sigma_g^2 + \sigma^2}\]</span></p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<h4 id="the-uncertainty-of-generalizability">The Uncertainty of Generalizability</h4>
<h4 id="simulated-data-1">Simulated Data</h4>
<h4 id="multidimensional-scale-1">Multidimensional Scale</h4>
<h4 id="limitations-of-g-theory">Limitations of G-theory</h4>
<h3 id="factor-analysis">Factor Analysis</h3>
<p>omega (as generalization of alpha), ave</p>
<h4 id="the-uncertainty-of-factor-loadings">The Uncertainty of Factor Loadings</h4>
<h4 id="simulated-data-2">Simulated Data</h4>
<h4 id="multidimensional-scale-2">Multidimensional Scale</h4>
<h4 id="limitations-of-factor-analytic-approach">Limitations of Factor Analytic Approach</h4>
<h2 id="conclusion-and-summary">Conclusion and Summary</h2>
<h2 id="appendix">Appendix</h2>
<h2 id="acknowledgments" class="appendix">Acknowledgments</h2>
<p>Yadda yadda</p>
<h2 id="author-contributions" class="appendix">Author Contributions</h2>
<p>Yadda yadda</p>
<div id="refs" class="references">
<div id="ref-feldt_statistical_1987">
<p>Feldt, Leonard S., David J. Woodruff, and Fathi A. Salih. 1987. “Statistical Inference for Coefficient Alpha.” <em>Applied Psychological Measurement</em> 11 (1): 93–103. <a href="https://doi.org/10.1177/014662168701100107">https://doi.org/10.1177/014662168701100107</a>.</p>
</div>
<div id="ref-kelley_confidence_2016">
<p>Kelley, Ken, and Sunthud Pornprasertmanit. 2016. “Confidence Intervals for Population Reliability Coefficients: Evaluation of Methods, Recommendations, and Software for Composite Measures.” <em>Psychological Methods</em> 21 (1): 69–92. <a href="https://doi.org/10.1037/a0040086">https://doi.org/10.1037/a0040086</a>.</p>
</div>
<div id="ref-mcdonald_test_1999">
<p>McDonald, Roderick. 1999. <em>Test Theory: A Unified Treatment</em>. Psychology Press. <a href="https://books.google.com/books/about/Test_Theory.html?id=_feqA2RdyOoC">https://books.google.com/books/about/Test_Theory.html?id=_feqA2RdyOoC</a>.</p>
</div>
<div id="ref-padilla_estimating_2011">
<p>Padilla, Miguel, and Guili Zhang. 2011. “Estimating Internal Consistency Using Bayesian Methods.” <em>Journal of Modern Applied Statistical Methods</em> 10 (1). <a href="https://doi.org/10.22237/jmasm/1304223840">https://doi.org/10.22237/jmasm/1304223840</a>.</p>
</div>
<div id="ref-revelle_introduction_nodate">
<p>Revelle, William. n.d. <em>An Introduction to Psychometric Theory with Applications in R</em>. Accessed December 4, 2018. <a href="http://www.personality-project.org/r/book/">http://www.personality-project.org/r/book/</a>.</p>
</div>
<div id="ref-zinbarg_cronbachs_2005">
<p>Zinbarg, Richard E., William Revelle, Iftah Yovel, and Wen Li. 2005. “Cronbach’s α, Revelle’s β, and Mcdonald’s ωH: Their Relations with Each Other and Two Alternative Conceptualizations of Reliability.” <em>Psychometrika</em> 70 (1): 123–33. <a href="https://doi.org/10.1007/s11336-003-0974-7">https://doi.org/10.1007/s11336-003-0974-7</a>.</p>
</div>
<div id="ref-van_zyl_distribution_2000">
<p>Zyl, J. M. van, H. Neudecker, and D. G. Nel. 2000. “On the Distribution of the Maximum Likelihood Estimator of Cronbach’s Alpha.” <em>Psychometrika</em> 65 (3): 271–80. <a href="https://doi.org/10.1007/BF02296146">https://doi.org/10.1007/BF02296146</a>.</p>
</div>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Despite the overconfidence shown in some disciplines of their measures. Unfortunately, ignoring it doesn’t mean it disappears.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Despite this, you will see it frequently reported in cases of multidimensional factor structure.<a href="#fnref2" class="footnote-back">↩</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
<h3 id="updates-and-corrections">Corrections</h3>
<p>If you see mistakes or want to suggest changes, please <a href="https://github.com/m-clark/reliability/issues/new">create an issue</a> on the source repository.</p>
<h3 id="citation">Citation</h3>
<p>For attribution, please cite this work as</p>
<pre class="citation-appendix short">Clark, et al. (2019, Jan. 8). reliability: The Uncertainty of Reliability. Retrieved from https://m-clark.github.io/reliability</pre>
<p>BibTeX citation</p>
<pre class="citation-appendix long">@misc{clark2019the,
  author = {Clark, Michael and Chen, Xilin and Berry, Seth and Errickson, Josh and Herrington, Richard and George, Brian C.},
  title = {reliability: The Uncertainty of Reliability},
  url = {https://m-clark.github.io/reliability},
  year = {2019}
}</pre>
</div>
<script id="distill-bibliography" type="text/bibtex">

@article{armor_theta_1973,
	title = {Theta {Reliability} and {Factor} {Scaling}},
	volume = {5},
	issn = {0081-1750},
	url = {http://www.jstor.org/stable/270831},
	doi = {10.2307/270831},
	urldate = {2018-12-19},
	journal = {Sociological Methodology},
	author = {Armor, David J.},
	year = {1973},
	pages = {17--50}
}

@article{kelley_confidence_2016,
	title = {Confidence intervals for population reliability coefficients: {Evaluation} of methods, recommendations, and software for composite measures.},
	volume = {21},
	issn = {1939-1463(Electronic),1082-989X(Print)},
	doi = {10.1037/a0040086},
	abstract = {A composite score is the sum of a set of components. For example, a total test score can be defined as the sum of the individual items. The reliability of composite scores is of interest in a wide variety of contexts due to their widespread use and applicability to many disciplines. The psychometric literature has devoted considerable time to discussing how to best estimate the population reliability value. However, all point estimates of a reliability coefficient fail to convey the uncertainty associated with the estimate as it estimates the population value. Correspondingly, a confidence interval is recommended to convey the uncertainty with which the population value of the reliability coefficient has been estimated. However, many confidence interval methods for bracketing the population reliability coefficient exist and it is not clear which method is most appropriate in general or in a variety of specific circumstances. We evaluate these confidence interval methods for 4 reliability coefficients (coefficient alpha, coefficient omega, hierarchical omega, and categorical omega) under a variety of conditions with 3 large-scale Monte Carlo simulation studies. Our findings lead us to generally recommend bootstrap confidence intervals for hierarchical omega for continuous items and categorical omega for categorical items. All of the methods we discuss are implemented in the freely available R language and environment via the MBESS package. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {1},
	journal = {Psychological Methods},
	author = {Kelley, Ken and Pornprasertmanit, Sunthud},
	year = {2016},
	keywords = {*Confidence Limits (Statistics), *Measurement, *Methodology, *Statistical Reliability, *Test Scores, Computer Software, Statistical Correlation},
	pages = {69--92}
}

@book{revelle_introduction_nodate,
	title = {An introduction to psychometric theory with applications in {R}},
	url = {http://www.personality-project.org/r/book/},
	urldate = {2018-12-04},
	author = {Revelle, William},
	file = {The Personality Project\: An introduction to psychometric theory:/Users/micl/Zotero/storage/LNWYTUNI/book.html:text/html}
}

@book{mcdonald_test_1999,
	title = {Test theory: {A} unified treatment},
	url = {https://books.google.com/books/about/Test_Theory.html?id=_feqA2RdyOoC},
	abstract = {This book introduces the reader to the main quantitative concepts, methods, and computational techniques needed for the development, evaluation, and application of tests in the behavioral/social sciences, including educational tests. Two empirical examples are carried throughout to illustrate alternative methods. Other data sets are used for special illustrations. Self-contained programs for confirmatory and exploratory factor analysis are available on the Web. Intended for students of psychology, particularly educational psychology, as well as social science students interested in how tests are constructed and used, prerequisites include a course on statistics. The programs and data files for this book can be downloaded from www.psypress.com/test-theory/},
	urldate = {2018-09-29},
	publisher = {Psychology Press},
	author = {McDonald, Roderick},
	year = {1999}
}

@article{padilla_estimating_2011,
	title = {Estimating {Internal} {Consistency} {Using} {Bayesian} {Methods}},
	volume = {10},
	issn = {1538 - 9472},
	url = {https://digitalcommons.wayne.edu/jmasm/vol10/iss1/25},
	doi = {10.22237/jmasm/1304223840},
	number = {1},
	journal = {Journal of Modern Applied Statistical Methods},
	author = {Padilla, Miguel and Zhang, Guili},
	month = may,
	year = {2011},
	file = {"Estimating Internal Consistency Using Bayesian Methods " by Miguel A. Padilla and Guili Zhang:/Users/micl/Zotero/storage/XSMF3VUT/25.html:text/html;Full Text:/Users/micl/Zotero/storage/S693H5X8/Padilla and Zhang - 2011 - Estimating Internal Consistency Using Bayesian Met.pdf:application/pdf}
}

@article{van_zyl_distribution_2000,
	title = {On the distribution of the maximum likelihood estimator of {Cronbach}'s alpha},
	volume = {65},
	issn = {1860-0980},
	url = {https://doi.org/10.1007/BF02296146},
	doi = {10.1007/BF02296146},
	abstract = {The asymptotic normal distribution of the maximum likelihood estimator of Cronbach's alpha (under normality) is derived for the case when no assumptions are made about the covariances among items. The asymptotic distribution is also considered for the special case of compound symmetry and compared to the exact distribution.},
	language = {en},
	number = {3},
	urldate = {2018-12-04},
	journal = {Psychometrika},
	author = {van Zyl, J. M. and Neudecker, H. and Nel, D. G.},
	month = sep,
	year = {2000},
	keywords = {compound symmetry, Cronbach's alpha, internal consistency, test reliability},
	pages = {271--280}
}

@misc{bonett_cronbachs_2015,
	title = {Cronbach's alpha reliability: {Interval} estimation, hypothesis testing, and sample size planning - {Bonett} - 2015 - {Journal} of {Organizational} {Behavior} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/job.1960},
	urldate = {2018-09-29},
	author = {Bonett},
	year = {2015}
}

@article{feldt_statistical_1987,
	title = {Statistical {Inference} for {Coefficient} {Alpha}},
	volume = {11},
	issn = {0146-6216},
	url = {https://doi.org/10.1177/014662168701100107},
	doi = {10.1177/014662168701100107},
	abstract = {Rigorous comparison of the reliability coefficients of several tests or measurement procedures requires a sampling theory for the coefficients. This paper sum marizes the important aspects of the sampling theory for Cronbach's (1951) coefficient alpha, a widely used internal consistency coefficient. This theory enables researchers to test a specific numerical hypothesis about the population alpha and to obtain confidence intervals for the population coefficient. It also permits researchers to test the hypothesis of equality among several coefficients, either under the condition of inde pendent samples or when the same sample has been used for all measurements. The procedures are illus trated numerically, and the assumptions and deriva tions underlying the theory are discussed.},
	language = {en},
	number = {1},
	urldate = {2018-12-02},
	journal = {Applied Psychological Measurement},
	author = {Feldt, Leonard S. and Woodruff, David J. and Salih, Fathi A.},
	month = mar,
	year = {1987},
	pages = {93--103}
}

@article{yuan_study_2003,
	title = {A {Study} {Of} {The} {Distribution} {Of} {Sample} {Coefficient} {Alpha} {With} {The} {Hopkins} {Symptom} {Checklist}: {Bootstrap} {Versus} {Asymptotics}},
	volume = {63},
	issn = {0013-1644},
	shorttitle = {A {Study} {Of} {The} {Distribution} {Of} {Sample} {Coefficient} {Alpha} {With} {The} {Hopkins} {Symptom} {Checklist}},
	url = {https://doi.org/10.1177/0013164402239314},
	doi = {10.1177/0013164402239314},
	abstract = {Sample coefficient alpha is commonly reported for psychological measurement scales. However, how to characterize the distribution of sample coefficient alpha with the Likert-type scales typically used in social and behavioral science research is not clear. Using the Hopkins Symptom Checklist, the authors compare three characterizations of the distribution of the sample coefficient alpha: the existing normal-theory-based distribution, a newly proposed distribution based on fourth-order moments, and the bootstrap empirical distribution. Their study indicates that the normal-theory-based distribution has a systematic bias in describing the behavior of the sample coefficient alpha. The distribution based on fourth-order moments is better than the normal-theory-based one but is still not good enough with finite samples. The bootstrap automatically takes the sampling distribution and sample size into account; thus it is recommended for characterizing the behavior of sample coefficient alpha with Likert-type scales.},
	language = {en},
	number = {1},
	urldate = {2018-09-30},
	journal = {Educational and Psychological Measurement},
	author = {Yuan, Ke-Hai and Guarnaccia, Charles A. and Hayslip, Bert},
	month = feb,
	year = {2003},
	pages = {5--23}
}

@article{kruschke_time_2012,
	title = {The {Time} {Has} {Come}: {Bayesian} {Methods} for {Data} {Analysis} in the {Organizational} {Sciences}},
	volume = {15},
	issn = {1094-4281},
	shorttitle = {The {Time} {Has} {Come}},
	url = {https://doi.org/10.1177/1094428112457829},
	doi = {10.1177/1094428112457829},
	abstract = {The use of Bayesian methods for data analysis is creating a revolution in fields ranging from genetics to marketing. Yet, results of our literature review, including more than 10,000 articles published in 15 journals from January 2001 and December 2010, indicate that Bayesian approaches are essentially absent from the organizational sciences. Our article introduces organizational science researchers to Bayesian methods and describes why and how they should be used. We use multiple linear regression as the framework to offer a step-by-step demonstration, including the use of software, regarding how to implement Bayesian methods. We explain and illustrate how to determine the prior distribution, compute the posterior distribution, possibly accept the null value, and produce a write-up describing the entire Bayesian process, including graphs, results, and their interpretation. We also offer a summary of the advantages of using Bayesian analysis and examples of how specific published research based on frequentist analysis-based approaches failed to benefit from the advantages offered by a Bayesian approach and how using Bayesian analyses would have led to richer and, in some cases, different substantive conclusions. We hope that our article will serve as a catalyst for the adoption of Bayesian methods in organizational science research.},
	language = {en},
	number = {4},
	urldate = {2018-09-30},
	journal = {Organizational Research Methods},
	author = {Kruschke, John K. and Aguinis, Herman and Joo, Harry},
	month = oct,
	year = {2012},
	pages = {722--752}
}

@misc{revelle_personality_nodate,
	title = {The {Personality} {Project}: {An} introduction to psychometric theory},
	url = {http://www.personality-project.org/r/book/},
	urldate = {2018-09-29},
	author = {Revelle, William}
}

@article{barbaranelli_problem_2015,
	title = {The {Problem} {With} {Cronbach}’s {Alpha}: {Comment} on {Sijtsma} and van der {Ark} (2015)},
	volume = {64},
	issn = {0029-6562},
	shorttitle = {The {Problem} {With} {Cronbach}’s {Alpha}},
	url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00006199-201503000-00009},
	doi = {10.1097/NNR.0000000000000079},
	language = {en},
	number = {2},
	urldate = {2018-09-29},
	journal = {Nursing Research},
	author = {Barbaranelli, Claudio and Lee, Christopher S. and Vellone, Ercole and Riegel, Barbara},
	year = {2015},
	pages = {140--145}
}

@article{sijtsma_conceptions_2015,
	title = {Conceptions of {Reliability} {Revisited} and {Practical} {Recommendations}},
	volume = {64},
	issn = {0029-6562},
	url = {https://journals.lww.com/nursingresearchonline/Fulltext/2015/03000/Conceptions_of_Reliability_Revisited_and_Practical.7.aspx},
	doi = {10.1097/NNR.0000000000000077},
	abstract = {We discuss reliability definitions from the perspectives of classical test theory, factor analysis, and generalizability theory. For each method, we discuss the rationale, the estimation of reliability, and the goodness of fit of the model that defines the reliability coefficient to the data. Similarities and differences in the three approaches are highlighted. Finally, we provide a computational example using generated data to illustrate the differences among the different reliability methods.},
	language = {en-US},
	number = {2},
	urldate = {2018-09-29},
	journal = {Nursing Research},
	author = {Sijtsma, Klaas and van der Ark, L. Andries},
	month = apr,
	year = {2015},
	pages = {128}
}

@article{sijtsma_use_2009,
	title = {On the {Use}, the {Misuse}, and the {Very} {Limited} {Usefulness} of {Cronbach}’s {Alpha}},
	volume = {74},
	issn = {0033-3123, 1860-0980},
	url = {http://link.springer.com/10.1007/s11336-008-9101-0},
	doi = {10.1007/s11336-008-9101-0},
	language = {en},
	number = {1},
	urldate = {2018-09-29},
	journal = {Psychometrika},
	author = {Sijtsma, Klaas},
	month = mar,
	year = {2009},
	pages = {107--120}
}

@article{tavakol_reliability_2017,
	title = {The reliability of assessments: {The} {Bayesian} {Cronbach}’s alpha},
	volume = {39},
	issn = {0142-159X, 1466-187X},
	shorttitle = {The reliability of assessments},
	url = {https://www.tandfonline.com/doi/full/10.1080/0142159X.2017.1296121},
	doi = {10.1080/0142159X.2017.1296121},
	language = {en},
	number = {5},
	urldate = {2018-09-29},
	journal = {Medical Teacher},
	author = {Tavakol, Mohsen},
	month = may,
	year = {2017},
	pages = {561--561}
}

@misc{tavakol_foundations_nodate,
	title = {The foundations of measurement and assessment in medical education: {Medical} {Teacher}: {Vol} 39, {No} 10},
	url = {https://www.tandfonline.com/doi/abs/10.1080/0142159X.2017.1359521},
	urldate = {2018-09-29},
	author = {Tavakol, Mohsen}
}

@article{revelle_coefficients_2009,
	title = {Coefficients {Alpha}, {Beta}, {Omega}, and the glb: {Comments} on {Sijtsma}},
	volume = {74},
	issn = {0033-3123, 1860-0980},
	shorttitle = {Coefficients {Alpha}, {Beta}, {Omega}, and the glb},
	url = {http://link.springer.com/10.1007/s11336-008-9102-z},
	doi = {10.1007/s11336-008-9102-z},
	language = {en},
	number = {1},
	urldate = {2018-09-29},
	journal = {Psychometrika},
	author = {Revelle, William and Zinbarg, Richard E.},
	month = mar,
	year = {2009},
	pages = {145--154}
}

@article{zinbarg_cronbachs_2005,
	title = {Cronbach’s α, {Revelle}’s β, and {Mcdonald}’s ω{H}: their relations with each other and two alternative conceptualizations of reliability},
	volume = {70},
	issn = {1860-0980},
	shorttitle = {Cronbach’s α, {Revelle}’s β, and {Mcdonald}’s ω{H}},
	url = {https://doi.org/10.1007/s11336-003-0974-7},
	doi = {10.1007/s11336-003-0974-7},
	abstract = {We make theoretical comparisons among five coefficients—Cronbach’s α, Revelle’s β, McDonald’s ω h , and two alternative conceptualizations of reliability. Though many end users and psychometricians alike may not distinguish among these five coefficients, we demonstrate formally their nonequivalence. Specifically, whereas there are conditions under which α, β, and ω h are equivalent to each other and to one of the two conceptualizations of reliability considered here, we show that equality with this conceptualization of reliability and between α and ω h holds only under a highly restrictive set of conditions and that the conditions under which β equals ω h are only somewhat more general. The nonequivalence of α, β, and ω h suggests that important information about the psychometric properties of a scale may be missing when scale developers and users only report α as is almost always the case},
	language = {en},
	number = {1},
	urldate = {2018-12-20},
	journal = {Psychometrika},
	author = {Zinbarg, Richard E. and Revelle, William and Yovel, Iftah and Li, Wen},
	month = mar,
	year = {2005},
	keywords = {Alternative Conceptualization, Psychometric Property, Public Policy, Statistical Theory, Theoretical Comparison},
	pages = {123--133},
	file = {Springer Full Text PDF:/Users/micl/Zotero/storage/PWZXY6Z2/Zinbarg et al. - 2005 - Cronbach’s α, Revelle’s β, and Mcdonald’s ωH thei.pdf:application/pdf}
}

@article{terry_sample_2012,
	title = {Sample size planning for composite reliability coefficients: {Accuracy} in parameter estimation via narrow confidence intervals},
	volume = {65},
	copyright = {©2011 The British Psychological Society},
	issn = {2044-8317},
	shorttitle = {Sample size planning for composite reliability coefficients},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8317.2011.02030.x},
	doi = {10.1111/j.2044-8317.2011.02030.x},
	abstract = {Composite measures play an important role in psychology and related disciplines. Composite measures almost always have error. Correspondingly, it is important to understand the reliability of the scores from any particular composite measure. However, the point estimates of the reliability of composite measures are fallible and thus all such point estimates should be accompanied by a confidence interval. When confidence intervals are wide, there is much uncertainty in the population value of the reliability coefficient. Given the importance of reporting confidence intervals for estimates of reliability, coupled with the undesirability of wide confidence intervals, we develop methods that allow researchers to plan sample size in order to obtain narrow confidence intervals for population reliability coefficients. We first discuss composite reliability coefficients and then provide a discussion on confidence interval formation for the corresponding population value. Using the accuracy in parameter estimation approach, we develop two methods to obtain accurate estimates of reliability by planning sample size. The first method provides a way to plan sample size so that the expected confidence interval width for the population reliability coefficient is sufficiently narrow. The second method ensures that the confidence interval width will be sufficiently narrow with some desired degree of assurance (e.g., 99\% assurance that the 95\% confidence interval for the population reliability coefficient will be less than W units wide). The effectiveness of our methods was verified with Monte Carlo simulation studies. We demonstrate how to easily implement the methods with easy-to-use and freely available software.},
	language = {en},
	number = {3},
	urldate = {2018-12-26},
	journal = {British Journal of Mathematical and Statistical Psychology},
	author = {Terry, Leann and Kelley, Ken},
	year = {2012},
	pages = {371--401},
	file = {Snapshot:/Users/micl/Zotero/storage/W5SZLDY6/j.2044-8317.2011.02030.html:text/html}
}

@article{kelley_confidence_2012,
	title = {Confidence intervals for population reliability coefficients: {Evaluation} of methods, recommendations, and software for composite measures.},
	volume = {8},
	url = {http://psycnet.apa.org/search/display?id=0e8f6328-2a4c-bc07-a8d1-73f18caec397&recordId=1&tab=PA&page=1&display=25&sort=PublicationYearMSSort%20desc,AuthorSort%20asc&sr=1},
	doi = {10.1027/1614-2241/a000036},
	abstract = {The reliability of a composite score is a fundamental and important topic in the social and behavioral sciences. The most commonly used reliability estimate of a composite score is coefficient α. However, under regularity conditions, the population value of coefficient α is only a lower bound on the population reliability, unless the items are essentially τ-equivalent, an assumption that is likely violated in most applications. A generalization of coefficient α, termed ω, is discussed and generally recommended. Furthermore, a point estimate itself almost certainly differs from the population value. Therefore, it is important to provide confidence interval limits so as not to overinterpret the point estimate. Analytic and bootstrap methods are described in detail for confidence interval construction for ω. We go on to recommend the bias-corrected bootstrap approach for ω and provide open source and freely available R functions via the MBESS package to implement the methods discussed.},
	number = {2},
	journal = {Methodology: European Journal of Research Methods for the Behavioral and Social Sciences},
	author = {Kelley, Ken and Chen, Ying},
	year = {2012},
	keywords = {*Confidence Limits (Statistics), *Measurement, *Methodology, *Statistical Reliability, *Test Scores, Computer Software, Statistical Correlation},
	pages = {39--50}
}
</script>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
