<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>reliability: The Uncertainty of Reliability</title>
  
  <meta property="description" itemprop="description" content="Notions of consistency"/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2019-06-17"/>
  <meta property="article:created" itemprop="dateCreated" content="2019-06-17"/>
  <meta name="article:author" content="Michael Clark"/>
  <meta name="article:author" content="Xilin Chen"/>
  <meta name="article:author" content="Seth Berry"/>
  <meta name="article:author" content="Josh Errickson"/>
  <meta name="article:author" content="Richard Herrington"/>
  <meta name="article:author" content="Brian C. George"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="reliability: The Uncertainty of Reliability"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Notions of consistency"/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:site_name" content="reliability"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="reliability: The Uncertainty of Reliability"/>
  <meta property="twitter:description" content="Notions of consistency"/>
  
  <!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
  <meta name="citation_title" content="reliability: The Uncertainty of Reliability"/>
  <meta name="citation_fulltext_html_url" content="https://m-clark.github.io/reliability"/>
  <meta name="citation_online_date" content="2019/06/17"/>
  <meta name="citation_publication_date" content="2019/06/17"/>
  <meta name="citation_author" content="Michael Clark"/>
  <meta name="citation_author_institution" content="University of Michigan, CSCAR"/>
  <meta name="citation_author" content="Xilin Chen"/>
  <meta name="citation_author_institution" content="University of Michigan, C-STAR"/>
  <meta name="citation_author" content="Seth Berry"/>
  <meta name="citation_author_institution" content="University of Notre Dame, Mendoza"/>
  <meta name="citation_author" content="Josh Errickson"/>
  <meta name="citation_author_institution" content="University of Michigan, CSCAR"/>
  <meta name="citation_author" content="Richard Herrington"/>
  <meta name="citation_author_institution" content="University of North Texas, DSA"/>
  <meta name="citation_author" content="Brian C. George"/>
  <meta name="citation_author_institution" content="University of Michigan, PLSC"/>
  <!--/radix_placeholder_meta_tags-->
  
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","bibliography","output","repository_url","citation_url"]}},"value":[{"type":"character","attributes":{},"value":["The Uncertainty of Reliability"]},{"type":"character","attributes":{},"value":["Notions of consistency\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Michael Clark"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io"]},{"type":"character","attributes":{},"value":["University of Michigan, CSCAR"]},{"type":"character","attributes":{},"value":["https://cscar.research.umich.edu/"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Xilin Chen"]},{"type":"character","attributes":{},"value":["https://www.procedurallearning.org/"]},{"type":"character","attributes":{},"value":["University of Michigan, C-STAR"]},{"type":"character","attributes":{},"value":["https://www.procedurallearning.org/"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Seth Berry"]},{"type":"character","attributes":{},"value":["https://mendoza.nd.edu/research-and-faculty/directory/seth-berry/"]},{"type":"character","attributes":{},"value":["University of Notre Dame, Mendoza"]},{"type":"character","attributes":{},"value":["https://mendoza.nd.edu/"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Josh Errickson"]},{"type":"character","attributes":{},"value":["https://errickson.net/"]},{"type":"character","attributes":{},"value":["University of Michigan, CSCAR"]},{"type":"character","attributes":{},"value":["https://cscar.research.umich.edu/"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Richard Herrington"]},{"type":"character","attributes":{},"value":["https://errickson.net/"]},{"type":"character","attributes":{},"value":["University of North Texas, DSA"]},{"type":"character","attributes":{},"value":["https://it.unt.edu/research/"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Brian C. George"]},{"type":"character","attributes":{},"value":["https://www.procedurallearning.org/"]},{"type":"character","attributes":{},"value":["University of Michigan, PLSC"]},{"type":"character","attributes":{},"value":["https://www.procedurallearning.org/"]}]}]},{"type":"character","attributes":{},"value":["2019-06-17"]},{"type":"character","attributes":{},"value":["measurement.bib"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["css","toc"]}},"value":[{"type":"character","attributes":{},"value":["radix.css"]},{"type":"logical","attributes":{},"value":[true]}]}]},{"type":"character","attributes":{},"value":["https://github.com/m-clark/reliability"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io/reliability"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  d-code {
    overflow-x: auto !important;
  }
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  
  d-code {
    overflow-x: visible !important;
  }
  
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="site_libs/htmlwidgets-1.3/htmlwidgets.js"></script>
  <script src="site_libs/viz-0.3/viz.js"></script>
  <link href="site_libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
  <script src="site_libs/grViz-binding-1.0.0/grViz.js"></script>
  <script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
  <script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->

  <link rel="stylesheet" href="radix.css" type="text/css"/>

</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"The Uncertainty of Reliability","description":"Notions of consistency","authors":[{"author":"Michael Clark","authorURL":"https://m-clark.github.io","affiliation":"University of Michigan, CSCAR","affiliationURL":"https://cscar.research.umich.edu/"},{"author":"Xilin Chen","authorURL":"https://www.procedurallearning.org/","affiliation":"University of Michigan, C-STAR","affiliationURL":"https://www.procedurallearning.org/"},{"author":"Seth Berry","authorURL":"https://mendoza.nd.edu/research-and-faculty/directory/seth-berry/","affiliation":"University of Notre Dame, Mendoza","affiliationURL":"https://mendoza.nd.edu/"},{"author":"Josh Errickson","authorURL":"https://errickson.net/","affiliation":"University of Michigan, CSCAR","affiliationURL":"https://cscar.research.umich.edu/"},{"author":"Richard Herrington","authorURL":"https://errickson.net/","affiliation":"University of North Texas, DSA","affiliationURL":"https://it.unt.edu/research/"},{"author":"Brian C. George","authorURL":"https://www.procedurallearning.org/","affiliation":"University of Michigan, PLSC","affiliationURL":"https://www.procedurallearning.org/"}],"publishedDate":"2019-06-17T00:00:00.000-04:00","citationText":"Clark, et al., 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>The Uncertainty of Reliability</h1>
<p>Notions of consistency</p>
</div>

<div class="d-byline">
  Michael Clark <a href="https://m-clark.github.io" class="uri">https://m-clark.github.io</a> (University of Michigan, CSCAR)<a href="https://cscar.research.umich.edu/" class="uri">https://cscar.research.umich.edu/</a>
  
,   Xilin Chen <a href="https://www.procedurallearning.org/" class="uri">https://www.procedurallearning.org/</a> (University of Michigan, C-STAR)<a href="https://www.procedurallearning.org/" class="uri">https://www.procedurallearning.org/</a>
  
,   Seth Berry <a href="https://mendoza.nd.edu/research-and-faculty/directory/seth-berry/" class="uri">https://mendoza.nd.edu/research-and-faculty/directory/seth-berry/</a> (University of Notre Dame, Mendoza)<a href="https://mendoza.nd.edu/" class="uri">https://mendoza.nd.edu/</a>
  
,   Josh Errickson <a href="https://errickson.net/" class="uri">https://errickson.net/</a> (University of Michigan, CSCAR)<a href="https://cscar.research.umich.edu/" class="uri">https://cscar.research.umich.edu/</a>
  
,   Richard Herrington <a href="https://errickson.net/" class="uri">https://errickson.net/</a> (University of North Texas, DSA)<a href="https://it.unt.edu/research/" class="uri">https://it.unt.edu/research/</a>
  
,   Brian C. George <a href="https://www.procedurallearning.org/" class="uri">https://www.procedurallearning.org/</a> (University of Michigan, PLSC)<a href="https://www.procedurallearning.org/" class="uri">https://www.procedurallearning.org/</a>
  
<br/>2019-06-17
</div>

<div class="d-article">
<h3 class="d-toc-header">Table of Contents</h3>
<nav class="d-toc" id="TOC">
<ul>
<li><a href="#the-meaning-of-reliability">The Meaning of Reliability</a><ul>
<li><a href="#what-we-talk-about-when-we-talk-about-reliability">What we talk about when we talk about reliability</a></li>
</ul></li>
<li><a href="#statistical-reliability">Statistical Reliability</a><ul>
<li><a href="#classical-test-theory">Classical Test Theory</a></li>
<li><a href="#correlation">Correlation</a></li>
<li><a href="#consistency">Consistency</a></li>
<li><a href="#measurement-of-a-construct">Measurement of a Construct</a></li>
<li><a href="#the-psychometric-definition-of-reliability">The psychometric definition of reliability</a></li>
</ul></li>
<li><a href="#demonstrations">Demonstrations</a><ul>
<li><a href="#preliminaries">Preliminaries</a></li>
<li><a href="#coefficient-alpha">Coefficient <span class="math inline">\(\alpha\)</span></a></li>
<li><a href="#generalizability-theory">Generalizability theory</a></li>
<li><a href="#factor-analysis">Factor Analysis</a></li>
</ul></li>
<li><a href="#conclusion-and-summary">Conclusion and Summary</a></li>
<li><a href="#appendix">Appendix</a></li>
<li><a href="#acknowledgments">Acknowledgments</a></li>
<li><a href="#author-contributions">Author Contributions</a></li>
</ul>
</nav>
<hr class="d-toc-separator"/>
<p><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.3/css/all.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous"></p>
<div style="text-align: center; font-size: 200%">
<strong>IN PROGRESS</strong>
</div>
<h4 id="goalsabstract">Goals/Abstract</h4>
<p>To examine reliability from different perspectives, and the uncertainty in the measurement of it.</p>
<h4 id="audience">Audience</h4>
<p>Applied practitioners of statistics in fields where the reporting of reliability of measurement is commonplace (e.g. psychology, education, biomedical sciences). Supplemental material may go deeper and be of interest to methodologists.</p>
<h2 id="the-meaning-of-reliability">The Meaning of Reliability</h2>
<h3 id="what-we-talk-about-when-we-talk-about-reliability">What we talk about when we talk about reliability</h3>
<p>When used in everyday discourse, no one really wonders what we mean when we say something is <span class="emph">reliable</span>. If you are talking about a car and you say it’s reliable, it means it won’t break down on you. If we talk about a person being reliable, it means we can depend on them to provide consistent behavior, e.g. regarding a specific task. Reliable electric service means one can keep the lights on all day. This everyday notion of reliability is closely related to the notion of dependability as well. We can depend on the person, car, or whatever, to do what we <em>expect</em>. Even though we may agree on this concept of reliability, pause should be taken. A reliable car from the 1970s would not meet acceptable standards for reliability these days. Your assessment and standard of reliablity may be wholly different if talking about a brother or sister. Thus, some fuzziness is inherent even with the everyday notion of reliability.</p>
<p>While we can talk about reliability from an everyday standpoint, the concept has been carried over to the realm of scientific analysis of data as well. And while the concept may be applied, it must of course become more precise, as scientific endeavor dictates. It may surprise some that reliability has been studied scientifically for over a century. With that knowledge however, it should not be too surprising that numerous statistical techniques have been advanced over that time, and the varieties will often align with different notions of reliability.</p>
<aside>
Charles Spearman (1904) examined the attenuation of correlation due to measurement error, but there were still earlier investigations. See Revelle chapter 7 for a brief history<span class="citation" data-cites="revelle_introduction_nodate">(Revelle <a href="#ref-revelle_introduction_nodate">n.d.</a>)</span>.
</aside>
<p>Even when positing a specific statistic for reliability, our investigation should not end there. As with the everyday notion of reliablity, there is <span class="emph">uncertainty</span> in the scientific measurement of it, and we should have some grasp of the nature of that uncertainty, else we risk becoming overly confident in our understanding of a measure. Thus what holds for other statistical measures - means, regression coefficients, and so on - will apply to any measurment of reliability as well.</p>
<p>In what follows we seek to trace out a few of the definitions of reliability associated with some of the more common statistical measures of it. Classical test theory will lay the foundation, after which we will explore an understanding of reliability from simple correlations, to the concept of consistency, and finally toward thinking about latent constructs and measurement error more deeply. Demonstrations of each notion of reliability will then be provided, not focused on merely producing a statistic, but establishing the uncertainty surrounding it, and understanding it with that context. General comparisons and contrasts about the different approaches will be made, and suggestions about practical ways to proceed offered. And finally, much more advanced and technical exploration will be undertaken in the supplemental addendum to this document.</p>
<h2 id="statistical-reliability">Statistical Reliability</h2>
<h3 id="classical-test-theory">Classical Test Theory</h3>
<p>The foundation for understanding reliability from a statistical standpoint resides with <span class="emph">Classical Test Theory</span>. The title may be offputting at first blush, but it is conceptually straightforward. Even then, as McDonald <span class="citation" data-cites="mcdonald_test_1999">McDonald (<a href="#ref-mcdonald_test_1999">1999</a>)</span> put it-</p>
<blockquote>
<p>The mathematics of the theory is extremely simple. The application of the theory can be problematic.</p>
</blockquote>
<p>So what are the mathematics? Simple arithmetic.</p>
<p><span class="math display">\[\mathrm{Observed\  Score = True\  Score + Error}\]</span></p>
<p>But what does this mean? Any measurement we take of something provides us an observed score. For example, we step on a scale and note our weight. A perfect measurement would provide the right score every time, and thus our observed score would equal the <span class="emph">true score</span>. But no measurement is perfect<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, i.e. everything is measured with some amount of <span class="emph">error</span>, however small. The error can be random, variability caused by unknown sources, but which will not affect our average account of a thing. Our weight from the scale goes up and down but on average it is correct. Error can also be systematic, where the measurement is always off by some amount, and our observed score is always too high or too low. In this scenario, our scale may always be displaying a greater weight than it should. Unfortunately, it is very difficult, if not impossible, to distinguish the two in many typical circumstances.</p>
<aside>
Note that by <span class="emph">test</span>, we mean any thing we might want to measure. The study of measurement was, after (psycho-)physics, largely dominated by education and psychology for decades, but needn’t be restricted to those domains.
</aside>
<p>So conceptually we can simply think of an observation of any measure being composed of whatever the true score would be plus some associated error. The key idea is that the assessment of the error will allow us to understand how reliable our measure is.</p>
<h3 id="correlation">Correlation</h3>
<p>Let’s start with correlation. If two things are correlated, they move in tandem, either they go up and down together, or as one goes up the other goes down and vice versa. At the very least of our understanding of reliability is that similar measurements of the same thing should be correlated. But this correlation might be assessed by different means.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="index_files/figure-html5/corplot-1.svg" width="75%" /></p>
</div>
<h4 id="test-retest">Test-retest</h4>
<div style="text-align: center;">
<p><i class="fas fa-file-alt fa-6x" style="color: #ff550095"></i> <i class="fas fa-file-alt fa-6x" style="color: #ff550095; border-style: solid; border-width: 1px; border-color: #ffffff; margin-left: -50px"></i> <i class="fas fa-file-alt fa-6x" style="color: #ff550095; border-style: solid; border-width: 1px; border-color: #ffffff; margin-left: -50px"></i></p>
</div>
<p>Let’s say we now take the weights of one hundred people. Then we do so again six months later. We should expect that heavier people at the first measurement will likely be heavier the second time as well. Same for lighter people.</p>
<p>That correlation of the two measurments can provide us our first attempt at measuring reliability. Typically referred to as test-retest reliability, this notion gives us some understanding of the stability or consistency of measurement <em>across time</em>. While this is useful and straightforward, many situations will not allow for multiple testing occasions, so we’ll need other alternatives.</p>
<h4 id="parallel-forms">Parallel Forms</h4>
<div style="text-align: center;">
<p><i class="fas fa-file-alt fa-6x" style="color: #ff5500BF "> </i> <span style=" display:inline-block; width:25px"></span> <i class="fas fa-file-alt fa-6x" style="color: #ff550080"></i> <span style=" display:inline-block; width:25px"></span> <i class="fas fa-file-alt fa-6x" style="color: #ff550040"></i></p>
</div>
<p>One method instructors used to use to thwart cheating was to provide half of the class one version of the test, and the other half a different version, that covered the same content, but which had slightly different questions/answers. When passed out randomly, students couldn’t peek at their neighbor’s test and gain any advantage. In terms of classical test theory, if we gave these parallel/alternate forms to each student, the true score for any student would be the same, regardless of what form they took, and any observed score differences would be error.</p>
<p>In the more common applied research setting, the question then is how do we know if we are dealing with parallel tests? Unless they are derived as such, we cannot say for certain, and this usually only happens in educational settings, such as with the SAT or GRE. Beyond that it is probably rare that resources allow for parallel forms of measurement, or if they do, enough forms to test the assumption of parallelism.</p>
<h4 id="split-half">Split-half</h4>
<div style="text-align: center;">
<p><img src="img/split_half.svg" style="display:block; margin: 0 auto; height: 6em; opacity: .75"></p>
</div>
<p>A notion of reliability not too far removed from the previous is that of split-half reliability. If our measure is made up of multiple observations, say, survey questions, scale items, or whatever, we can just take a random half of them, get a total score for each individual, and do the same with the other half. Now each person has two scores, and their correlation gives us a glimpse of the reliability of the measure. Consider it a poor man’s alternate forms approach.</p>
<h3 id="consistency">Consistency</h3>
<div style="text-align: center;">
<p><i class="fas fa-file-alt fa-6x" style="color: #ff5500BF"></i> <span style=" display:inline-block; width:25px"></span> <i class="fas fa-long-arrow-alt-right fa-4x" style="color: lightgray;  vertical-align: text-bottom"></i> <span style=" display:inline-block; width:25px"></span> <i class="fas fa-question fa-5x" style="color: #ff550095; border-style: solid; border-width: 1px; border-color: #ffffff; vertical-align: text-bottom"></i></p>
</div>
<p>Split-half reliability allows us to estimate reliability with only one test. This is important, as many times we can only measure something in one setting, even if multiple times within that setting. For example, there may be only one qualifying exam, one survey administered, and so forth. As such we need some way to assess the <span class="emph">internal structure</span> of the measure. Some of the most commonly used statistics, such as coefficient <span class="math inline">\(\alpha\)</span>, offer such a measure. For that, it will still be based on simple correlations, but as we don’t have multiple tests, the correlations will regard the items or instances of the measure we have from the setting observations occur. The average correlation across all items will serve as the basis for an assessment of reliability, but the number of items will have a say as well.</p>
<h3 id="measurement-of-a-construct">Measurement of a Construct</h3>
<div class="layout-chunk" data-layout="l-body">
<div style="width:50%; margin:0 auto; font-family:Roboto; font-size:50%">
<div id="htmlwidget-153ef7dfab6f466a323a" style="width:100%;height:250px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-153ef7dfab6f466a323a">{"x":{"diagram":"digraph Factor  {\n graph [rankdir=TB  bgcolor=transparent]\n node [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 shape=box width=.5 color=\"#ff5500\"];\n edge [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 color=\"#00aaff80\" style=\"dashed\"];\n X1  [label = \"X1\"];\n X2  [label = \"X2\"];\n X3  [label = \"X3\"];\n X4  [label = \"X4\"];\n X5  [label = \"X5\"];\n\n node [shape=circle width=1];\n   C [label = \"?\" style=filled color=\"#00aaff\", fillcolor=\"#ff550080\" fontcolor=\"#fffff8\" fontsize=32];\n   C -> X1  ;\n   C -> X2  ;\n   C -> X3  ;\n   C -> X4  ;\n   C -> X5  ;\n \n { rank=same; \n X1; X2; X3; X4; X5; }\n \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>Finally, we can think about reliability in terms of how well the tests measure the construct. Some would call this validity, though the distinction is muddier in practice. The observed measurements we have are imperfect measurements of the thing they are purported to measure. Estimation of that imperfection is the whole of reliability analysis. We can get at this notion more intently with tools from <span class="emph">factor analysis</span>, and can begin to think about reliability in terms of how much of the <em>latent</em> constuct is actually in the observed measures.</p>
<h3 id="the-psychometric-definition-of-reliability">The psychometric definition of reliability</h3>
<p>We can summarize all of the previous by returning to the classical test theory notion of reliability. In general, the reliability of a measure <span class="math inline">\(\rho\)</span> is the proportion of true score variance to the total observed variance.</p>
<p><span class="math display">\[\rho = \frac{\sigma^2_T}{\sigma^2_T + \sigma^2_e}\]</span></p>
<h2 id="demonstrations">Demonstrations</h2>
<h3 id="preliminaries">Preliminaries</h3>
<p>Before diving into demonstration we will first describe the data and analytical approach. Both observed and simulated data will be presented, followed by discussion of the analysis.</p>
<h4 id="data-description">Data Description</h4>
<h5 id="observed-data">Observed Data</h5>
<p>The Big Five Inventory is a popular personality scale use in a wide variety of applications. For our example, we will have at our disposal 25 items corresponding to the five subscales- Agreeableness, Openness, Extroversion, Conscientiousness, and Neuroticism. However, we will concern ourselves with the Neurtocism subscale specifically. This particular data is available in the R package <span class="pack">psych</span>, and regards 2800 subjects as part of the Synthetic Aperture Personality Assessment (SAPA) web based personality assessment project. The items are six-point scales ranging from 1 Very Inaccurate to six 6 Very Accurate, and are statements that may reflect the person’s assessment of themselves. The neuroticism items in particular are:</p>
<ul>
<li>N1: Get angry easily.</li>
<li>N2: Get irritated easily.</li>
<li>N3: Have frequent mood swings.</li>
<li>N4: Often feel blue.</li>
<li>N5: Panic easily.</li>
</ul>
<p>More details can be found with the data object’s (<span class="objclass">bfi</span>) associated helpfile. The following shows how the data may be obtained. To make comparisons across the different approaches more easily comparable, I go ahead and remove the rows with missing data.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(tidyverse)
library(psych)
neuroticism = bfi %&gt;% 
  select(N1:N5) %&gt;% 
  drop_na()</code></pre>
</div>
<blockquote>
<p>Use only small fraction and compare to full in later discusion of sample size?</p>
</blockquote>
<p>Basic descriptives and correlations are shown next. While there is some missing data, some reliability statistics will be based on pairwise correlations, and thus use all available information. Some of the item correlations are not that strong, but this is a realistic situation for many data in social and related sciences.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:right;">
N
</th>
<th style="text-align:right;">
Mean
</th>
<th style="text-align:right;">
SD
</th>
<th style="text-align:right;">
Median
</th>
<th style="text-align:right;">
Missing
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
N1
</td>
<td style="text-align:right;">
2694
</td>
<td style="text-align:right;">
2.93
</td>
<td style="text-align:right;">
1.57
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
N2
</td>
<td style="text-align:right;">
2694
</td>
<td style="text-align:right;">
3.51
</td>
<td style="text-align:right;">
1.53
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
N3
</td>
<td style="text-align:right;">
2694
</td>
<td style="text-align:right;">
3.22
</td>
<td style="text-align:right;">
1.60
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
N4
</td>
<td style="text-align:right;">
2694
</td>
<td style="text-align:right;">
3.19
</td>
<td style="text-align:right;">
1.57
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
N5
</td>
<td style="text-align:right;">
2694
</td>
<td style="text-align:right;">
2.97
</td>
<td style="text-align:right;">
1.62
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
N1
</th>
<th style="text-align:right;">
N2
</th>
<th style="text-align:right;">
N3
</th>
<th style="text-align:right;">
N4
</th>
<th style="text-align:right;">
N5
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
N1
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.71
</td>
<td style="text-align:right;">
0.56
</td>
<td style="text-align:right;">
0.40
</td>
<td style="text-align:right;">
0.38
</td>
</tr>
<tr>
<td style="text-align:left;">
N2
</td>
<td style="text-align:right;">
0.71
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.55
</td>
<td style="text-align:right;">
0.39
</td>
<td style="text-align:right;">
0.35
</td>
</tr>
<tr>
<td style="text-align:left;">
N3
</td>
<td style="text-align:right;">
0.56
</td>
<td style="text-align:right;">
0.55
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.52
</td>
<td style="text-align:right;">
0.43
</td>
</tr>
<tr>
<td style="text-align:left;">
N4
</td>
<td style="text-align:right;">
0.40
</td>
<td style="text-align:right;">
0.39
</td>
<td style="text-align:right;">
0.52
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.40
</td>
</tr>
<tr>
<td style="text-align:left;">
N5
</td>
<td style="text-align:right;">
0.38
</td>
<td style="text-align:right;">
0.35
</td>
<td style="text-align:right;">
0.43
</td>
<td style="text-align:right;">
0.40
</td>
<td style="text-align:right;">
1.00
</td>
</tr>
</tbody>
</table>
</div>
<h5 id="simulatedideal-data">Simulated/Ideal data</h5>
<p>One of our investigations into reliability will involve what is commonly referred to as factor analysis. Along with the observed data just described, the <span class="pack">psych</span> package additionally provides an easy means to simulate data with known factor structure. We can specify the number of factors, loadings, number of items among other things. Doing so will allow us to know what to expect from the factor analysis portion of the exploration, and explore uni- vs. multidimensional structure if desired. As a starting point, we will simulate a data set regarding a <span class="emph">congeneric</span> factor model, one in which the factor structure regards just one latent variable underlying the observed items, but where the loadings for the observations need not be the same. We will have six items for this data, with moderate to strong loadings between .4 and .7.</p>
<aside>
In the case where the loadings are equivalent, the model is referred to as <span class="emph">tau-equivalent</span>.
</aside>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
set.seed(123)
N = 1000
n_items = 6
loadings_congeneric = c(.4, .4, .5, .5, .6, .7)

cor_congeneric = sim.congeneric(loadings_congeneric, N = N)

data_congeneric = 
  mvtnorm::rmvnorm(n = N, 
                   mean = rep(0, n_items), 
                   sigma = cor_congeneric) %&gt;% 
  as_data_frame() %&gt;% 
  rename_all(str_replace, pattern = &#39;V&#39;, replacement = &#39;item_&#39;)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
item_1
</th>
<th style="text-align:right;">
item_2
</th>
<th style="text-align:right;">
item_3
</th>
<th style="text-align:right;">
item_4
</th>
<th style="text-align:right;">
item_5
</th>
<th style="text-align:right;">
item_6
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
-1.158
</td>
<td style="text-align:right;">
0.592
</td>
<td style="text-align:right;">
2.019
</td>
<td style="text-align:right;">
0.797
</td>
<td style="text-align:right;">
1.869
</td>
<td style="text-align:right;">
0.329
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.038
</td>
<td style="text-align:right;">
1.193
</td>
<td style="text-align:right;">
0.635
</td>
<td style="text-align:right;">
0.845
</td>
<td style="text-align:right;">
0.108
</td>
<td style="text-align:right;">
0.213
</td>
</tr>
<tr>
<td style="text-align:right;">
0.398
</td>
<td style="text-align:right;">
0.211
</td>
<td style="text-align:right;">
0.828
</td>
<td style="text-align:right;">
-0.138
</td>
<td style="text-align:right;">
-0.534
</td>
<td style="text-align:right;">
1.333
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.712
</td>
<td style="text-align:right;">
0.194
</td>
<td style="text-align:right;">
-1.546
</td>
<td style="text-align:right;">
-0.551
</td>
<td style="text-align:right;">
1.944
</td>
<td style="text-align:right;">
0.084
</td>
</tr>
<tr>
<td style="text-align:right;">
0.839
</td>
<td style="text-align:right;">
0.521
</td>
<td style="text-align:right;">
-1.203
</td>
<td style="text-align:right;">
0.798
</td>
<td style="text-align:right;">
-0.822
</td>
<td style="text-align:right;">
0.606
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.098
</td>
<td style="text-align:right;">
-0.047
</td>
<td style="text-align:right;">
0.429
</td>
<td style="text-align:right;">
-0.356
</td>
<td style="text-align:right;">
-0.116
</td>
<td style="text-align:right;">
0.364
</td>
</tr>
</tbody>
</table>
</div>
<h4 id="analytical-approach">Analytical Approach</h4>
<p>The analysis of the data will be conducted on both the observed and simulated data sets. We will show three conceptual estimates of reliability, but, in addition, we will focus on the estimated uncertainty in those estimates. Far too often reliability statistics are reported without any thought of the underlying models, or that there is possibly notable uncertainty in the estimate. The three conceptual estimates include the most popular estimate of reliability, Coefficient <span class="math inline">\(\alpha\)</span>, followed by two model-based approaches - generalizability theory and latent variable/factor analysis.</p>
<h3 id="coefficient-alpha">Coefficient <span class="math inline">\(\alpha\)</span></h3>
<p>Coefficient <span class="math inline">\(\alpha\)</span> is one of the most popular measures of reliability. Sometimes considered a measure of <span class="emph">internal consistency</span>, it is a function of the average covariance/correlation among the observations/items, the total variance of the test, as well as the number of items. It is also interpreted as the average of all possible spit-half reliabilities. While it is descriptive in nature, it actually assumes a unidimensional factor structure as the underlying model representation, or in other words, that all the items correspond to the same underlying construct<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>. The standardized formula only requires the two values of the number of items <span class="math inline">\(k\)</span> and average inter-item correlation <span class="math inline">\(\bar{r}\)</span>.</p>
<aside>
Though it was developed independently a few years earlier by Guttman <span class="citation" data-cites="guttman_basis_1945">Guttman (<a href="#ref-guttman_basis_1945">1945</a>)</span>, coefficient <span class="math inline">\(\alpha\)</span> is often called Cronbach’s <span class="math inline">\(\alpha\)</span>. We prefer the more neutral terminology, in keeping with Cronbach’s own wishes <span class="citation" data-cites="cronbach_my_2004">Cronbach and Shavelson (<a href="#ref-cronbach_my_2004">2004</a>)</span>.
</aside>
<p><span class="math display">\[\alpha = \frac{k\bar{r}}{1+(k-1)\bar{r}}\]</span></p>
<p>All else being equal, simply increasing the number of observations/items will give you a higher reliability. In some contexts this may make sense, as the goal is to use an average or sum score, and we are interested in the reliability of that instead of any particular item. In other contexts such an estimate may overestimate the type of reliability we care about.</p>
<aside>
The raw score formula for <span class="math inline">\(\alpha\)</span> in terms of the average variance of the items <span class="math inline">\(\bar{v}\)</span> and average covariance <span class="math inline">\(\bar{c}\)</span> is: <span class="math display">\[\alpha = \frac{k\bar{c}}{\bar{v}+(k-1)\bar{c}}\]</span>
</aside>
<p>The following shows the results from the <span class="pack">psych</span> package. In addition to both raw and standardized <span class="math inline">\(\alpha\)</span> measures, it also offers Guttman’s lambda 6, a ‘signal-to-noise’ ratio and tohre info. Shown are the <span class="math inline">\(\alpha\)</span> values, absolute standard error, and average/median inter-item correlation.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
Raw
</th>
<th style="text-align:right;">
Standardized
</th>
<th style="text-align:right;">
Avg. Inter-item cor
</th>
<th style="text-align:right;">
Median r
</th>
<th style="text-align:right;">
ASE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.47
</td>
<td style="text-align:right;">
0.41
</td>
<td style="text-align:right;">
0.01
</td>
</tr>
</tbody>
</table>
</div>
<p>These statistics show how <span class="math inline">\(\alpha\)</span> changes when the item is dropped. We can see that items N1 through N3 are more useful measures, as dropping them would result in a significant drop in <span class="math inline">\(\alpha\)</span>.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
(#tab:cronbach_drop)Reliability if the item is dropped.
</caption>
<thead>
<tr>
<th style="text-align:right;">
Raw
</th>
<th style="text-align:right;">
Standardized
</th>
<th style="text-align:right;">
Avg. Inter-item cor
</th>
<th style="text-align:right;">
Median r
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.76
</td>
<td style="text-align:right;">
0.76
</td>
<td style="text-align:right;">
0.44
</td>
<td style="text-align:right;">
0.41
</td>
</tr>
<tr>
<td style="text-align:right;">
0.76
</td>
<td style="text-align:right;">
0.76
</td>
<td style="text-align:right;">
0.45
</td>
<td style="text-align:right;">
0.41
</td>
</tr>
<tr>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.76
</td>
<td style="text-align:right;">
0.44
</td>
<td style="text-align:right;">
0.39
</td>
</tr>
<tr>
<td style="text-align:right;">
0.79
</td>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
0.49
</td>
<td style="text-align:right;">
0.49
</td>
</tr>
<tr>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.52
</td>
<td style="text-align:right;">
0.53
</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<h4 id="the-uncertainty-of-alpha">The Uncertainty of <span class="math inline">\(\alpha\)</span></h4>
<p>One issue with Coefficient <span class="math inline">\(\alpha\)</span> is that the uncertainty in the estimate is rarely reported, even though it has been known for some time how to derive a confidence interval for it, and tools are readily available for producing it. The <span class="pack">MBESS</span> package does this in a variety ways. One uses an approach noted in Feldt et al. <span class="citation" data-cites="feldt_statistical_1987">Feldt, Woodruff, and Salih (<a href="#ref-feldt_statistical_1987">1987</a>)</span>, and which assumes fixed, rather than random, items and subjects. Another is based on a normal distribution approximation <span class="citation" data-cites="van_zyl_distribution_2000">Zyl, Neudecker, and Nel (<a href="#ref-van_zyl_distribution_2000">2000</a>)</span>. The other method is via the bootstrap <span class="citation" data-cites="kelley_confidence_2016">Kelley and Pornprasertmanit (<a href="#ref-kelley_confidence_2016">2016</a>)</span>, calculating <span class="math inline">\(\alpha\)</span> for <span class="math inline">\(R\)</span> number of bootstrap resamples of the data. We will use the latter for our purposes. Results are shown below, with the bootstrapped value based on 1000 iterations.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
LL
</th>
<th style="text-align:right;">
alpha
</th>
<th style="text-align:right;">
UL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
bootstrapped estimate
</td>
<td style="text-align:right;">
0.8004
</td>
<td style="text-align:right;">
0.8133
</td>
<td style="text-align:right;">
0.8253
</td>
</tr>
</tbody>
</table>
</div>
<p>We can now see that our estimate of <span class="math inline">\(\alpha\)</span> would best be summarized as some value between 0.80 and 0.83.</p>
<h5 id="a-bayesian-approach">A Bayesian Approach</h5>
<p>An alternative approach to estimating the uncertainty in <span class="math inline">\(\alpha\)</span> would be a Bayesian estimate. We could estimate the value by first estimating the correlation matrix underlying the assumed multivariate normal distribution of the observations/items. Thus the Bayesian <span class="math inline">\(\alpha\)</span> would be based on the posterior predictive distribution given the estimate of the correlation matrix <span class="citation" data-cites="padilla_estimating_2011">Padilla and Zhang (<a href="#ref-padilla_estimating_2011">2011</a>)</span>. Alternatively, we could use a normal approximation for the distribution of the <span class="math inline">\(\alpha\)</span> itself, based on the estimated correlation matrix <span class="citation" data-cites="van_zyl_distribution_2000">(<a href="#ref-van_zyl_distribution_2000">2000</a>)</span>. Yet another approach would be based on a mixed model, calculating an <span class="emph">intra-class correlation coefficent</span> for a set number of items, as in Generalizability theory. We will save that for its own section later. For now, we will use the first estimate. More detail can be found in the supplemental materials.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
LL
</th>
<th style="text-align:right;">
alpha
</th>
<th style="text-align:right;">
UL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
normal bayes
</td>
<td style="text-align:right;">
0.789
</td>
<td style="text-align:right;">
0.813
</td>
<td style="text-align:right;">
0.839
</td>
</tr>
<tr>
<td style="text-align:left;">
post. pred.
</td>
<td style="text-align:right;">
0.804
</td>
<td style="text-align:right;">
0.813
</td>
<td style="text-align:right;">
0.822
</td>
</tr>
<tr>
<td style="text-align:left;">
post. pred. non-normal
</td>
<td style="text-align:right;">
0.807
</td>
<td style="text-align:right;">
0.816
</td>
<td style="text-align:right;">
0.824
</td>
</tr>
</tbody>
</table>
</div>
<p>We can also view these estimates directly. The normal approximation is wider than the other two.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="index_files/figure-html5/vis_alpha_bayes-1.svg" width="75%" /></p>
</div>
<p>Here are all the estimates of uncertainty calculated. For this amount of data it is not surprising that they are mostly in agreement, though the normal approximation may be a little wider.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
LL
</th>
<th style="text-align:right;">
alpha
</th>
<th style="text-align:right;">
UL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
bootstrapped estimate
</td>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.83
</td>
</tr>
<tr>
<td style="text-align:left;">
normal bayes
</td>
<td style="text-align:right;">
0.79
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.84
</td>
</tr>
<tr>
<td style="text-align:left;">
post. pred.
</td>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.82
</td>
</tr>
<tr>
<td style="text-align:left;">
post. pred. non-normal
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.82
</td>
<td style="text-align:right;">
0.82
</td>
</tr>
</tbody>
</table>
<p><img src="index_files/figure-html5/alpha_all-1.svg" width="75%" /></p>
</div>
<h4 id="simulated-data">Simulated Data</h4>
<p>The simulated data allows for us to have a more controlled exploration. We know the items are multivariate normal and unidimensional, so this is where <span class="math inline">\(\alpha\)</span> shines as a measure of reliability. However, one assumption with coefficient <span class="math inline">\(\alpha\)</span> is that the loadings for such a model are equivalent, and we know they aren’t in this case. As such, coefficient <span class="math inline">\(\alpha\)</span> is an estimate of the lower bound of reliability <span class="citation" data-cites="revelle_coefficients_2009">Revelle and Zinbarg (<a href="#ref-revelle_coefficients_2009">2009</a>)</span> This scenario will serve as a comparison when we actually look at factor analytic approaches to reliability estimation later.</p>
<p>For now, we’ll skip the formality and cut right to the chase. Here are all the previous estimates shown for this data set. The <span class="math inline">\(\alpha\)</span> is lower for this particular data, but in general we’re seeing the same thing.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
LL
</th>
<th style="text-align:right;">
alpha
</th>
<th style="text-align:right;">
UL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
boot
</td>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
0.75
</td>
</tr>
<tr>
<td style="text-align:left;">
feldt
</td>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
0.75
</td>
</tr>
<tr>
<td style="text-align:left;">
normal
</td>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
0.75
</td>
</tr>
<tr>
<td style="text-align:left;">
normal bayes
</td>
<td style="text-align:right;">
0.67
</td>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
0.76
</td>
</tr>
<tr>
<td style="text-align:left;">
post. pred.
</td>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
0.74
</td>
</tr>
<tr>
<td style="text-align:left;">
post. pred. non-normal
</td>
<td style="text-align:right;">
0.71
</td>
<td style="text-align:right;">
0.73
</td>
<td style="text-align:right;">
0.75
</td>
</tr>
</tbody>
</table>
<p><img src="index_files/figure-html5/alpha_compare_congeneric-1.svg" width="75%" /></p>
</div>
<h4 id="comparison-to-small-sample">Comparison to small sample</h4>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Size
</th>
<th style="text-align:right;">
LL
</th>
<th style="text-align:right;">
alpha
</th>
<th style="text-align:right;">
UL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
10%
</td>
<td style="text-align:right;">
0.816
</td>
<td style="text-align:right;">
0.848
</td>
<td style="text-align:right;">
0.874
</td>
</tr>
<tr>
<td style="text-align:left;">
5%
</td>
<td style="text-align:right;">
0.793
</td>
<td style="text-align:right;">
0.841
</td>
<td style="text-align:right;">
0.878
</td>
</tr>
</tbody>
</table>
</div>
<h4 id="multidimensional-scale">Multidimensional Scale</h4>
<p>Notes: can’t generalize from subscale to whole or vice versa, alpha &lt; reliability in this setting <span class="citation" data-cites="zinbarg_cronbachs_2005">Zinbarg et al. (<a href="#ref-zinbarg_cronbachs_2005">2005</a>)</span></p>
<div class="layout-chunk" data-layout="l-body">

<pre><code>
Some items ( N1 N2 N3 N4 N5 O4 ) were negatively correlated with the total scale and 
probably should be reversed.  
To do this, run the function again with the &#39;check.keys=TRUE&#39; option</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
Raw
</th>
<th style="text-align:right;">
Standardized
</th>
<th style="text-align:right;">
Avg. Inter-item cor
</th>
<th style="text-align:right;">
Median r
</th>
<th style="text-align:right;">
ASE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
0.71
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
0.01
</td>
</tr>
</tbody>
</table>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Scale
</th>
<th style="text-align:right;">
Alpha
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Neuro
</td>
<td style="text-align:right;">
0.813
</td>
</tr>
<tr>
<td style="text-align:left;">
Extra
</td>
<td style="text-align:right;">
0.762
</td>
</tr>
<tr>
<td style="text-align:left;">
Open
</td>
<td style="text-align:right;">
0.600
</td>
</tr>
<tr>
<td style="text-align:left;">
Agree
</td>
<td style="text-align:right;">
0.703
</td>
</tr>
<tr>
<td style="text-align:left;">
Consc
</td>
<td style="text-align:right;">
0.727
</td>
</tr>
</tbody>
</table>
</div>
<h4 id="limitations-of-coefficient-alpha">Limitations of Coefficient <span class="math inline">\(\alpha\)</span></h4>
<ul>
<li>Assumes an underlying single factor model with equal loadings for items</li>
<li>Unless the assumptions, <span class="math inline">\(\alpha\)</span> can only provide a lower bound estimate</li>
<li>Merely adding items will improve the estimate, which may not be how we think about reliability for a given scenario</li>
<li>Internal consistency can be low even measures are stable across time; see <code>?psych::epiR</code> for example.</li>
</ul>
<h3 id="generalizability-theory">Generalizability theory</h3>
<p>So called <span class="emph">mixed effects models</span> are statistical models applicable to situations in which there is some dependency among observations in the data, where that correlation typically arises from the observations being clustered in some way. For example, it is quite common to have data in which we have repeated measurements of individuals, or cases in which the units of observation are otherwise grouped together, for example, students within school, or cities within geographic region. This clustering can be hierarchical in nature (e.g. students within schools, schools within districts) or not (e.g. students and items on a test). While there are different ways to approach such a situation, mixed models are a powerful tool with which to do so.</p>
<p>Mixed models estimate the variance attributable to the various sources of dependency in the data. Thus, aside from the usual regression output, we get a sense of variability due to individuals, species, surgical procedure, or whatever our grouping structure may be that produces the multiple observations. In addition, we may estimate cluster-specific effects, which allow for increased predictive capability. For example, in a longitudinal setting we may know the general trend across all individuals, but we can also allow each individual to have separate starting points and trends.</p>
<p>In our data example, each person sees the five items, so those scores within each person are not independent. In other words, the multiple observations are clustered within individuals. This becomes more clear when we consider our data in ‘long’ format, as follows.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
neuroticism_long = neuroticism %&gt;% 
  rowid_to_column(var=&#39;person&#39;) %&gt;%          # create person id
  gather(key = item, value=score, -person)   # melt data into long format</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
person
</th>
<th style="text-align:left;">
item
</th>
<th style="text-align:right;">
score
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
N1
</td>
<td style="text-align:right;">
3
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
N2
</td>
<td style="text-align:right;">
4
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
N3
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
N4
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
N5
</td>
<td style="text-align:right;">
3
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
N1
</td>
<td style="text-align:right;">
3
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
N2
</td>
<td style="text-align:right;">
3
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
N3
</td>
<td style="text-align:right;">
3
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
N4
</td>
<td style="text-align:right;">
5
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
N5
</td>
<td style="text-align:right;">
5
</td>
</tr>
</tbody>
</table>
</div>
<p>In similar fashion, we can see observations <em>within items</em> as being more correlated than observations within other items. As such, in this case we can treat the person or item as a source of variance, or in other settings, even their interaction.</p>
<p><span class="emph">Generalizability Theory</span> focuses on the variance components resulting from a linear mixed model. Using the variance estimates we can obtain a measure of the reliability of a mean score for an individual across the multiple observations. This reliability is defined as what proportion of the total variance is attributable to the particular source of variance, e.g. person, we wish to study. For some grouping or clustering factor <span class="math inline">\(g\)</span>, the simplest estimate of reliability (<span class="math inline">\(\rho\)</span>) would be calculated as follows:</p>
<p><span class="math display">\[\rho = \frac{\sigma_g^2}{\sigma_g^2 +  \sigma_{residual}^2}\]</span></p>
<aside>
Many will recognize this as the <strong>ICC</strong> or <span class="emph">intraclass correlation coefficient</span>.
</aside>
<p>In more complicated circumstances:</p>
<p><span class="math display">\[\rho = \frac{\sigma_g^2 + \sigma_{g*}^2}{\sigma_g^2 + \sigma_{g*}^2 + \sigma_{other}^2 + \sigma_{residual}^2}\]</span></p>
<p>In the above, <span class="math inline">\(g*\)</span> refers to interactions of g with other other sources of variance, <span class="math inline">\(other\)</span> refers to other still other sources of variance that don’t include <span class="math inline">\(g*\)</span>, and then the <span class="math inline">\(residual\)</span> variance is whatever else is not accounted for.</p>
<p>Generalizability theory distinguishes between two main statistical estimates of reliability: <span class="emph">dependability</span> which is calculated as above, and <span class="emph">generalizability</span> which would not include the <span class="math inline">\(\sigma_{other}^2\)</span> sources of variance. The former regards the reliability of ‘absolute’ measures, e.g. when we are interested in the specific score for an observation/individual. The latter regards a ‘relative’ measure, for example, when we are primarily interested only in whether the individual scores higher than another or passes some arbitrary cutoff score. If there is only one source of variance to consider, the statistics are identical, but otherwise dependability will always be less if the other sources of variances are non-negligible.</p>
<aside>
If you’re like me, the the absolute vs. relative distinction may not be as conceptually clear as you’d like. However, this is as much description as you’ll find in the texts.
</aside>
<p>Generalizability theory denotes two types of ‘study’, the <span class="emph">g-study</span>, or generalizability study, and the <span class="emph">d-study</span>, or decision study. The first simply calculates the basic dependability and/or generalizability statistic for a given data setting. The latter is concerned with the reliability of the mean or sum score over the set of <span class="math inline">\(N\)</span> possible observations. In this case, our above formulas would be altered to the following:</p>
<p><span class="math display">\[\rho = \frac{\sigma_g^2}{\sigma_g^2 +  \frac{\sigma_{residual}^2}{n_{obs}}}\]</span></p>
<p><span class="math display">\[\rho = \frac{\sigma_g^2 + \sigma_{g*}^2}{\sigma_g^2 + \frac{{\sigma_{g*}^2}}{n_{g*}} + \frac{\sigma_{other}^2}{n_{other}} + \frac{\sigma_{residual}^2}{n_{obs}}}\]</span></p>
<aside>
With unbalanced/typical data, what the <span class="math inline">\(n\_\)</span> should be is not straightforward. One could use the mean number of observations seen across clusters, the geometric mean (as in Brennan <span class="citation" data-cites="brennan">(<span class="citeproc-not-found" data-reference-id="brennan"><strong>???</strong></span>)</span>), or median (e.g. <span class="pack">gtheory</span> package in R). But these will definitely give you potentially very different estimates of reliability. Furthermore, beyond the simple mixed model setting, where we might have random slopes, other distributions for the response besides normal, etc. it becomes even muddier on what to do with these statistics.
</aside>
<p>The main take home point is that we have a more reliable measure dealing with a mean score of multiple observations than we do a single observation. We can set the various <span class="math inline">\(n\_*\)</span> to whatever we like. This allows us to see how many observations are needed to get to a certain level of reliability, assuming the variance components are held constant.</p>
<p>For simplicity we will focus only on the person variance in our examples. To calculate it we will use <span class="pack">lme4</span> to run the mixed model using the long form data.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(lme4)
model_gtheory = lmer(score ~ item + (1|person), neuroticism_long)
summary(model_gtheory, cor=F)</code></pre>
<pre><code>
Linear mixed model fit by REML [&#39;lmerMod&#39;]
Formula: score ~ item + (1 | person)
   Data: neuroticism_long

REML criterion at convergence: 46639.9

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.1901 -0.6359 -0.0488  0.6185  3.4780 

Random effects:
 Groups   Name        Variance Std.Dev.
 person   (Intercept) 1.161    1.078   
 Residual             1.333    1.154   
Number of obs: 13470, groups:  person, 2694

Fixed effects:
            Estimate Std. Error t value
(Intercept)  2.93133    0.03043  96.340
itemN2       0.57721    0.03146  18.350
itemN3       0.28545    0.03146   9.074
itemN4       0.25835    0.03146   8.213
itemN5       0.04195    0.03146   1.333</code></pre>
</div>
<p>Let’s just focus on the variance components, which allow us to calculate the g-coefficient. First we note the proportion of variance accounted for by the individuals.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
grp
</th>
<th style="text-align:right;">
vcov
</th>
<th style="text-align:right;">
sdcor
</th>
<th style="text-align:right;">
prop
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
person
</td>
<td style="text-align:right;">
1.161
</td>
<td style="text-align:right;">
1.078
</td>
<td style="text-align:right;">
0.466
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:right;">
1.333
</td>
<td style="text-align:right;">
1.154
</td>
<td style="text-align:right;">
0.534
</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>This proportion is 0.47. In other contexts this is called the <span class="emph">intraclass correlation</span> coefficient, which tells us also how correlated observations are within clusters. Some also call this <span class="emph">repeatability</span>.</p>
<p>However, while this does give us a sense of the reliability of the measure, it is only that of a single observation/item. If we want the generalizability coefficient, we need to divide the residual variance by the number of observations seen by each person. While we normally have missing data, to keep things simple we’ll just assume the complete data case. This would give us 1.161 / (1.161 + 1.333 / 5), or 0.813.</p>
<p>That is not a typo. In this context the generalizability value is identical to the coefficient <span class="math inline">\(\alpha\)</span>. As such, we have a new context within which to understand <span class="math inline">\(\alpha\)</span>, as the reliability of the average score over <span class="math inline">\(n\)</span> items. Likewise we can understand generalizability in the context of coefficient <span class="math inline">\(\alpha\)</span> and the underlying assumptions it has. However, generalizability theory provides additional means to estimate generalizability/dependability in more complicated settings.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<h4 id="the-uncertainty-of-generalizability">The Uncertainty of Generalizability</h4>
<p>The lme4 package provides a way to get an estimate of the uncertainty in the variance components,</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
model_gtheory_interval = confint(model_gtheory)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Component
</th>
<th style="text-align:left;">
2.5%
</th>
<th style="text-align:left;">
97.5%
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Person
</td>
<td style="text-align:left;">
1.04
</td>
<td style="text-align:left;">
1.11
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:left;">
1.14
</td>
<td style="text-align:left;">
1.17
</td>
</tr>
</tbody>
</table>
</div>
<p>which should imply that any estimate using them would also have uncertainty. How will we calculate the uncertainty in the g-coefficient?</p>
<h4 id="simulated-data-1">Simulated Data</h4>
<h4 id="multidimensional-scale-1">Multidimensional Scale</h4>
<h4 id="limitations-of-g-theory">Limitations of G-theory</h4>
<ul>
<li>unbalanced designs mean harmonic geometric median</li>
<li>random slopes</li>
<li>non-normal</li>
</ul>
<h3 id="factor-analysis">Factor Analysis</h3>
<p>With <span class="emph">factor analysis</span>, or <span class="emph">latent variable modeling</span>, we seek to find hidden variables that can explain the ones we observe. Take our current example with neuroticism. There is no direct measurement of neuroticism. However, we can ask several questions that get at the idea of it, and presumably these items will be notably correlated if they do measure the underlying construct well. Factor analysis will help us determine just how well the observed variables, and allows us to understand a single contruct rather than possibly many items.</p>
<aside>
Factor analysis can also be grouped under a broad heading of dimension reduction techniques that include principal components analysis, mixture models, latent dirichlet allocation, and more.
</aside>
<p>As with classical test theory, we generally assume that the observed variables are random observations of the construct, such that repeated analysis would produce the same thing. For example, the five neuroticism items are random draws from 25, and we should get the same thing more or less, regardless of which handful of items we choose. More generally, the 25 items are drawn from a universe of items that could be used to measure the latent variable. This notion would hold to other scenarios of repeated measures or clustered observations in general.</p>
<div class="layout-chunk" data-layout="l-body">
<div style="width:50%; margin:0 auto; font-family:Roboto; font-size:50%">
<div id="htmlwidget-1deb37f5f5021a14ea09" style="width:100%;height:250px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-1deb37f5f5021a14ea09">{"x":{"diagram":"digraph Factor  {\n graph [rankdir=TB  bgcolor=transparent]\n node [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 shape=box width=.5 color=\"#ff5500\"];\n edge [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 color=\"#00aaff80\" style=\"dashed\"];\n X1  [label = \"Anger\"];\n X2  [label = \"Irritated\"];\n X3  [label = \"Mood Swings\"];\n X4  [label = \"Feel Blue\"];\n X5  [label = \"Panic\"];\n\n node [shape=circle width=1];\n   C [label = \"Neuroticism\" style=filled color=\"#00aaff\", fillcolor=\"#ff550080\" fontcolor=\"#fffff8\" fontsize=14];\n   C -> X1  ;\n   C -> X2  ;\n   C -> X3  ;\n   C -> X4  ;\n   C -> X5  ;\n \n { rank=same; \n X1; X2; X3; X4; X5; }\n \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>Conducting factor analysis involves estimating the correlations implied by the paths from the latent construct to the observed variables (called <span class="emph">loadings</span>), as we well as estimating the (residual) variance of each item and (usually) the latent variable itself. The latent variable is assumed to have mean 0 and scaled arbitrarily to the first item, or simply standardized to have unit variance.</p>
<p>Factor analysis can be said to take on a more <span class="emph">structured</span> approach, versus one that is more <span class="emph">exploratory</span> and data-driven. If we have only a single construct these are indistinguishable. But let’s say we are developing this personality measure for the first time. Theory would suggest five total constructs, but since we in a testing stage, we may simply let the data decide how many factors there should be based on some criterion. In the structured approach, by contrast, we would only let the items we think measure neuroticism load on a neuroticism latent variable, and likewise for the other constructs. The following shows how this might look for two factors.</p>
<div class="layout-chunk" data-layout="l-body">
<div style="width:100%; margin:0 auto; font-family:Roboto; font-size:75%">
<div id="htmlwidget-8718ebefd2f0864cfa34" style="width:100%;height:500px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-8718ebefd2f0864cfa34">{"x":{"diagram":"digraph Factor  {\n graph [rankdir=LR  bgcolor=transparent]\n node [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 shape=box width=2 color=\"#ff5500\"];\n edge [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 color=\"#00aaff\"];\n A1  [label = \"A1\"];\n A2  [label = \"A2\"];\n A3  [label = \"A3\"];\n A4  [label = \"A4\"];\n A5  [label = \"A5\"];\n N1  [label = \"N1\"];\n N2  [label = \"N2\"];\n N3  [label = \"N3\"];\n N4  [label = \"N4\"];\n N5  [label = \"N5\"];\n\n node [shape=ellipse width=1];\n   Agree -> A1  ; #[label = -0.5];\n   Agree -> A2  ; #[label = 0.8];\n   Agree -> A3  ; #[label = 0.8];\n   Agree -> A4  ; #[label = 0.6];\n   Agree -> A5  ; #[label = 0.7];\n   Neuro -> N1  ; #[label = 0.8];\n   Neuro -> N2  ; #[label = 0.8];\n   Neuro -> N3  ; #[label = 0.7];\n   Neuro -> N4  ; #[label = 0.7];\n   Neuro -> N5  ; #[label = 0.5];\n \n Agree -> Neuro [arrowhead=\"both\"]\n \n { rank=same;\n A1; A2; A3; A4; A5; \n N1; N2; N3; N4; N5; }\n { rank=same;\n Neuro; Agree; \n }\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>We will keep things simple for our purposes starting out. Conducting a factor analysis can be very simple, and we will do so just for the neuroticism data as before.</p>
<p>omega (as generalization of alpha), ave</p>
<h4 id="the-uncertainty-of-factor-loadings">The Uncertainty of Factor Loadings</h4>
<h4 id="simulated-data-2">Simulated Data</h4>
<h4 id="multidimensional-scale-2">Multidimensional Scale</h4>
<h4 id="limitations-of-factor-analytic-approach">Limitations of Factor Analytic Approach</h4>
<h2 id="conclusion-and-summary">Conclusion and Summary</h2>
<h2 id="appendix">Appendix</h2>
<h2 id="acknowledgments" class="appendix">Acknowledgments</h2>
<p>Yadda yadda</p>
<h2 id="author-contributions" class="appendix">Author Contributions</h2>
<p>Yadda yadda</p>
<div id="refs" class="references">
<div id="ref-cronbach_my_2004">
<p>Cronbach, Lee J., and Richard J. Shavelson. 2004. “My Current Thoughts on Coefficient Alpha and Successor Procedures.” <em>Educational and Psychological Measurement</em> 64 (3): 391–418. <a href="https://doi.org/10.1177/0013164404266386">https://doi.org/10.1177/0013164404266386</a>.</p>
</div>
<div id="ref-feldt_statistical_1987">
<p>Feldt, Leonard S., David J. Woodruff, and Fathi A. Salih. 1987. “Statistical Inference for Coefficient Alpha.” <em>Applied Psychological Measurement</em> 11 (1): 93–103. <a href="https://doi.org/10.1177/014662168701100107">https://doi.org/10.1177/014662168701100107</a>.</p>
</div>
<div id="ref-guttman_basis_1945">
<p>Guttman, Louis. 1945. “A Basis for Analyzing Test-Retest Reliability.” <em>Psychometrika</em> 10 (4): 255–82. <a href="https://doi.org/10.1007/BF02288892">https://doi.org/10.1007/BF02288892</a>.</p>
</div>
<div id="ref-kelley_confidence_2016">
<p>Kelley, Ken, and Sunthud Pornprasertmanit. 2016. “Confidence Intervals for Population Reliability Coefficients: Evaluation of Methods, Recommendations, and Software for Composite Measures.” <em>Psychological Methods</em> 21 (1): 69–92. <a href="https://doi.org/10.1037/a0040086">https://doi.org/10.1037/a0040086</a>.</p>
</div>
<div id="ref-mcdonald_test_1999">
<p>McDonald, Roderick. 1999. <em>Test Theory: A Unified Treatment</em>. Psychology Press. <a href="https://books.google.com/books/about/Test_Theory.html?id=_feqA2RdyOoC">https://books.google.com/books/about/Test_Theory.html?id=_feqA2RdyOoC</a>.</p>
</div>
<div id="ref-padilla_estimating_2011">
<p>Padilla, Miguel, and Guili Zhang. 2011. “Estimating Internal Consistency Using Bayesian Methods.” <em>Journal of Modern Applied Statistical Methods</em> 10 (1). <a href="https://doi.org/10.22237/jmasm/1304223840">https://doi.org/10.22237/jmasm/1304223840</a>.</p>
</div>
<div id="ref-revelle_introduction_nodate">
<p>Revelle, William. n.d. <em>An Introduction to Psychometric Theory with Applications in R</em>. Accessed December 4, 2018. <a href="http://www.personality-project.org/r/book/">http://www.personality-project.org/r/book/</a>.</p>
</div>
<div id="ref-revelle_coefficients_2009">
<p>Revelle, William, and Richard E. Zinbarg. 2009. “Coefficients Alpha, Beta, Omega, and the Glb: Comments on Sijtsma.” <em>Psychometrika</em> 74 (1): 145–54. <a href="https://doi.org/10.1007/s11336-008-9102-z">https://doi.org/10.1007/s11336-008-9102-z</a>.</p>
</div>
<div id="ref-zinbarg_cronbachs_2005">
<p>Zinbarg, Richard E., William Revelle, Iftah Yovel, and Wen Li. 2005. “Cronbach’s α, Revelle’s β, and Mcdonald’s ωH: Their Relations with Each Other and Two Alternative Conceptualizations of Reliability.” <em>Psychometrika</em> 70 (1): 123–33. <a href="https://doi.org/10.1007/s11336-003-0974-7">https://doi.org/10.1007/s11336-003-0974-7</a>.</p>
</div>
<div id="ref-van_zyl_distribution_2000">
<p>Zyl, J. M. van, H. Neudecker, and D. G. Nel. 2000. “On the Distribution of the Maximum Likelihood Estimator of Cronbach’s Alpha.” <em>Psychometrika</em> 65 (3): 271–80. <a href="https://doi.org/10.1007/BF02296146">https://doi.org/10.1007/BF02296146</a>.</p>
</div>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Despite the overconfidence shown in some disciplines of their measures. Unfortunately, ignoring it doesn’t mean it disappears.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Despite this, you will see it frequently reported in cases of multidimensional factor structure.<a href="#fnref2" class="footnote-back">↩</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
<h3 id="updates-and-corrections">Corrections</h3>
<p>If you see mistakes or want to suggest changes, please <a href="https://github.com/m-clark/reliability/issues/new">create an issue</a> on the source repository.</p>
<h3 id="citation">Citation</h3>
<p>For attribution, please cite this work as</p>
<pre class="citation-appendix short">Clark, et al. (2019, June 17). reliability: The Uncertainty of Reliability. Retrieved from https://m-clark.github.io/reliability</pre>
<p>BibTeX citation</p>
<pre class="citation-appendix long">@misc{clark2019the,
  author = {Clark, Michael and Chen, Xilin and Berry, Seth and Errickson, Josh and Herrington, Richard and George, Brian C.},
  title = {reliability: The Uncertainty of Reliability},
  url = {https://m-clark.github.io/reliability},
  year = {2019}
}</pre>
</div>
<script id="distill-bibliography" type="text/bibtex">

@article{revelle_coefficients_2009,
	title = {Coefficients {Alpha}, {Beta}, {Omega}, and the glb: {Comments} on {Sijtsma}},
	volume = {74},
	issn = {0033-3123, 1860-0980},
	shorttitle = {Coefficients {Alpha}, {Beta}, {Omega}, and the glb},
	url = {http://link.springer.com/10.1007/s11336-008-9102-z},
	doi = {10.1007/s11336-008-9102-z},
	language = {en},
	number = {1},
	urldate = {2018-09-29},
	journal = {Psychometrika},
	author = {Revelle, William and Zinbarg, Richard E.},
	month = mar,
	year = {2009},
	pages = {145--154}
}

@misc{tavakol_foundations_nodate,
	title = {The foundations of measurement and assessment in medical education: {Medical} {Teacher}: {Vol} 39, {No} 10},
	url = {https://www.tandfonline.com/doi/abs/10.1080/0142159X.2017.1359521},
	urldate = {2018-09-29},
	author = {Tavakol, Mohsen}
}

@article{tavakol_reliability_2017,
	title = {The reliability of assessments: {The} {Bayesian} {Cronbach}’s alpha},
	volume = {39},
	issn = {0142-159X, 1466-187X},
	shorttitle = {The reliability of assessments},
	url = {https://www.tandfonline.com/doi/full/10.1080/0142159X.2017.1296121},
	doi = {10.1080/0142159X.2017.1296121},
	language = {en},
	number = {5},
	urldate = {2018-09-29},
	journal = {Medical Teacher},
	author = {Tavakol, Mohsen},
	month = may,
	year = {2017},
	pages = {561--561}
}

@book{mcdonald_test_1999,
	title = {Test theory: {A} unified treatment},
	url = {https://books.google.com/books/about/Test_Theory.html?id=_feqA2RdyOoC},
	abstract = {This book introduces the reader to the main quantitative concepts, methods, and computational techniques needed for the development, evaluation, and application of tests in the behavioral/social sciences, including educational tests. Two empirical examples are carried throughout to illustrate alternative methods. Other data sets are used for special illustrations. Self-contained programs for confirmatory and exploratory factor analysis are available on the Web. Intended for students of psychology, particularly educational psychology, as well as social science students interested in how tests are constructed and used, prerequisites include a course on statistics. The programs and data files for this book can be downloaded from www.psypress.com/test-theory/},
	urldate = {2018-09-29},
	publisher = {Psychology Press},
	author = {McDonald, Roderick},
	year = {1999}
}

@misc{bonett_cronbachs_2015,
	title = {Cronbach's alpha reliability: {Interval} estimation, hypothesis testing, and sample size planning - {Bonett} - 2015 - {Journal} of {Organizational} {Behavior} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/job.1960},
	urldate = {2018-09-29},
	author = {Bonett},
	year = {2015}
}

@article{sijtsma_use_2009,
	title = {On the {Use}, the {Misuse}, and the {Very} {Limited} {Usefulness} of {Cronbach}’s {Alpha}},
	volume = {74},
	issn = {0033-3123, 1860-0980},
	url = {http://link.springer.com/10.1007/s11336-008-9101-0},
	doi = {10.1007/s11336-008-9101-0},
	language = {en},
	number = {1},
	urldate = {2018-09-29},
	journal = {Psychometrika},
	author = {Sijtsma, Klaas},
	month = mar,
	year = {2009},
	pages = {107--120}
}

@article{sijtsma_conceptions_2015,
	title = {Conceptions of {Reliability} {Revisited} and {Practical} {Recommendations}},
	volume = {64},
	issn = {0029-6562},
	url = {https://journals.lww.com/nursingresearchonline/Fulltext/2015/03000/Conceptions_of_Reliability_Revisited_and_Practical.7.aspx},
	doi = {10.1097/NNR.0000000000000077},
	abstract = {We discuss reliability definitions from the perspectives of classical test theory, factor analysis, and generalizability theory. For each method, we discuss the rationale, the estimation of reliability, and the goodness of fit of the model that defines the reliability coefficient to the data. Similarities and differences in the three approaches are highlighted. Finally, we provide a computational example using generated data to illustrate the differences among the different reliability methods.},
	language = {en-US},
	number = {2},
	urldate = {2018-09-29},
	journal = {Nursing Research},
	author = {Sijtsma, Klaas and van der Ark, L. Andries},
	month = apr,
	year = {2015},
	pages = {128}
}

@article{barbaranelli_problem_2015,
	title = {The {Problem} {With} {Cronbach}’s {Alpha}: {Comment} on {Sijtsma} and van der {Ark} (2015)},
	volume = {64},
	issn = {0029-6562},
	shorttitle = {The {Problem} {With} {Cronbach}’s {Alpha}},
	url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00006199-201503000-00009},
	doi = {10.1097/NNR.0000000000000079},
	language = {en},
	number = {2},
	urldate = {2018-09-29},
	journal = {Nursing Research},
	author = {Barbaranelli, Claudio and Lee, Christopher S. and Vellone, Ercole and Riegel, Barbara},
	year = {2015},
	pages = {140--145}
}

@misc{revelle_personality_nodate,
	title = {The {Personality} {Project}: {An} introduction to psychometric theory},
	url = {http://www.personality-project.org/r/book/},
	urldate = {2018-09-29},
	author = {Revelle, William}
}

@article{kruschke_time_2012,
	title = {The {Time} {Has} {Come}: {Bayesian} {Methods} for {Data} {Analysis} in the {Organizational} {Sciences}},
	volume = {15},
	issn = {1094-4281},
	shorttitle = {The {Time} {Has} {Come}},
	url = {https://doi.org/10.1177/1094428112457829},
	doi = {10.1177/1094428112457829},
	abstract = {The use of Bayesian methods for data analysis is creating a revolution in fields ranging from genetics to marketing. Yet, results of our literature review, including more than 10,000 articles published in 15 journals from January 2001 and December 2010, indicate that Bayesian approaches are essentially absent from the organizational sciences. Our article introduces organizational science researchers to Bayesian methods and describes why and how they should be used. We use multiple linear regression as the framework to offer a step-by-step demonstration, including the use of software, regarding how to implement Bayesian methods. We explain and illustrate how to determine the prior distribution, compute the posterior distribution, possibly accept the null value, and produce a write-up describing the entire Bayesian process, including graphs, results, and their interpretation. We also offer a summary of the advantages of using Bayesian analysis and examples of how specific published research based on frequentist analysis-based approaches failed to benefit from the advantages offered by a Bayesian approach and how using Bayesian analyses would have led to richer and, in some cases, different substantive conclusions. We hope that our article will serve as a catalyst for the adoption of Bayesian methods in organizational science research.},
	language = {en},
	number = {4},
	urldate = {2018-09-30},
	journal = {Organizational Research Methods},
	author = {Kruschke, John K. and Aguinis, Herman and Joo, Harry},
	month = oct,
	year = {2012},
	pages = {722--752}
}

@article{yuan_study_2003,
	title = {A {Study} {Of} {The} {Distribution} {Of} {Sample} {Coefficient} {Alpha} {With} {The} {Hopkins} {Symptom} {Checklist}: {Bootstrap} {Versus} {Asymptotics}},
	volume = {63},
	issn = {0013-1644},
	shorttitle = {A {Study} {Of} {The} {Distribution} {Of} {Sample} {Coefficient} {Alpha} {With} {The} {Hopkins} {Symptom} {Checklist}},
	url = {https://doi.org/10.1177/0013164402239314},
	doi = {10.1177/0013164402239314},
	abstract = {Sample coefficient alpha is commonly reported for psychological measurement scales. However, how to characterize the distribution of sample coefficient alpha with the Likert-type scales typically used in social and behavioral science research is not clear. Using the Hopkins Symptom Checklist, the authors compare three characterizations of the distribution of the sample coefficient alpha: the existing normal-theory-based distribution, a newly proposed distribution based on fourth-order moments, and the bootstrap empirical distribution. Their study indicates that the normal-theory-based distribution has a systematic bias in describing the behavior of the sample coefficient alpha. The distribution based on fourth-order moments is better than the normal-theory-based one but is still not good enough with finite samples. The bootstrap automatically takes the sampling distribution and sample size into account; thus it is recommended for characterizing the behavior of sample coefficient alpha with Likert-type scales.},
	language = {en},
	number = {1},
	urldate = {2018-09-30},
	journal = {Educational and Psychological Measurement},
	author = {Yuan, Ke-Hai and Guarnaccia, Charles A. and Hayslip, Bert},
	month = feb,
	year = {2003},
	pages = {5--23}
}

@article{feldt_statistical_1987,
	title = {Statistical {Inference} for {Coefficient} {Alpha}},
	volume = {11},
	issn = {0146-6216},
	url = {https://doi.org/10.1177/014662168701100107},
	doi = {10.1177/014662168701100107},
	abstract = {Rigorous comparison of the reliability coefficients of several tests or measurement procedures requires a sampling theory for the coefficients. This paper sum marizes the important aspects of the sampling theory for Cronbach's (1951) coefficient alpha, a widely used internal consistency coefficient. This theory enables researchers to test a specific numerical hypothesis about the population alpha and to obtain confidence intervals for the population coefficient. It also permits researchers to test the hypothesis of equality among several coefficients, either under the condition of inde pendent samples or when the same sample has been used for all measurements. The procedures are illus trated numerically, and the assumptions and deriva tions underlying the theory are discussed.},
	language = {en},
	number = {1},
	urldate = {2018-12-02},
	journal = {Applied Psychological Measurement},
	author = {Feldt, Leonard S. and Woodruff, David J. and Salih, Fathi A.},
	month = mar,
	year = {1987},
	pages = {93--103}
}

@article{van_zyl_distribution_2000,
	title = {On the distribution of the maximum likelihood estimator of {Cronbach}'s alpha},
	volume = {65},
	issn = {1860-0980},
	url = {https://doi.org/10.1007/BF02296146},
	doi = {10.1007/BF02296146},
	abstract = {The asymptotic normal distribution of the maximum likelihood estimator of Cronbach's alpha (under normality) is derived for the case when no assumptions are made about the covariances among items. The asymptotic distribution is also considered for the special case of compound symmetry and compared to the exact distribution.},
	language = {en},
	number = {3},
	urldate = {2018-12-04},
	journal = {Psychometrika},
	author = {van Zyl, J. M. and Neudecker, H. and Nel, D. G.},
	month = sep,
	year = {2000},
	keywords = {compound symmetry, Cronbach's alpha, internal consistency, test reliability},
	pages = {271--280}
}

@article{padilla_estimating_2011,
	title = {Estimating {Internal} {Consistency} {Using} {Bayesian} {Methods}},
	volume = {10},
	issn = {1538 - 9472},
	url = {https://digitalcommons.wayne.edu/jmasm/vol10/iss1/25},
	doi = {10.22237/jmasm/1304223840},
	number = {1},
	journal = {Journal of Modern Applied Statistical Methods},
	author = {Padilla, Miguel and Zhang, Guili},
	month = may,
	year = {2011},
	file = {"Estimating Internal Consistency Using Bayesian Methods " by Miguel A. Padilla and Guili Zhang:/Users/micl/Zotero/storage/XSMF3VUT/25.html:text/html;Full Text:/Users/micl/Zotero/storage/S693H5X8/Padilla and Zhang - 2011 - Estimating Internal Consistency Using Bayesian Met.pdf:application/pdf}
}

@book{revelle_introduction_nodate,
	title = {An introduction to psychometric theory with applications in {R}},
	url = {http://www.personality-project.org/r/book/},
	urldate = {2018-12-04},
	author = {Revelle, William},
	file = {The Personality Project\: An introduction to psychometric theory:/Users/micl/Zotero/storage/LNWYTUNI/book.html:text/html}
}

@article{kelley_confidence_2016,
	title = {Confidence intervals for population reliability coefficients: {Evaluation} of methods, recommendations, and software for composite measures.},
	volume = {21},
	issn = {1939-1463(Electronic),1082-989X(Print)},
	doi = {10.1037/a0040086},
	abstract = {A composite score is the sum of a set of components. For example, a total test score can be defined as the sum of the individual items. The reliability of composite scores is of interest in a wide variety of contexts due to their widespread use and applicability to many disciplines. The psychometric literature has devoted considerable time to discussing how to best estimate the population reliability value. However, all point estimates of a reliability coefficient fail to convey the uncertainty associated with the estimate as it estimates the population value. Correspondingly, a confidence interval is recommended to convey the uncertainty with which the population value of the reliability coefficient has been estimated. However, many confidence interval methods for bracketing the population reliability coefficient exist and it is not clear which method is most appropriate in general or in a variety of specific circumstances. We evaluate these confidence interval methods for 4 reliability coefficients (coefficient alpha, coefficient omega, hierarchical omega, and categorical omega) under a variety of conditions with 3 large-scale Monte Carlo simulation studies. Our findings lead us to generally recommend bootstrap confidence intervals for hierarchical omega for continuous items and categorical omega for categorical items. All of the methods we discuss are implemented in the freely available R language and environment via the MBESS package. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {1},
	journal = {Psychological Methods},
	author = {Kelley, Ken and Pornprasertmanit, Sunthud},
	year = {2016},
	keywords = {*Confidence Limits (Statistics), *Measurement, *Methodology, *Statistical Reliability, *Test Scores, Computer Software, Statistical Correlation},
	pages = {69--92}
}

@article{armor_theta_1973,
	title = {Theta {Reliability} and {Factor} {Scaling}},
	volume = {5},
	issn = {0081-1750},
	url = {http://www.jstor.org/stable/270831},
	doi = {10.2307/270831},
	urldate = {2018-12-19},
	journal = {Sociological Methodology},
	author = {Armor, David J.},
	year = {1973},
	pages = {17--50}
}

@article{zinbarg_cronbachs_2005,
	title = {Cronbach’s α, {Revelle}’s β, and {Mcdonald}’s ω{H}: their relations with each other and two alternative conceptualizations of reliability},
	volume = {70},
	issn = {1860-0980},
	shorttitle = {Cronbach’s α, {Revelle}’s β, and {Mcdonald}’s ω{H}},
	url = {https://doi.org/10.1007/s11336-003-0974-7},
	doi = {10.1007/s11336-003-0974-7},
	abstract = {We make theoretical comparisons among five coefficients—Cronbach’s α, Revelle’s β, McDonald’s ω h , and two alternative conceptualizations of reliability. Though many end users and psychometricians alike may not distinguish among these five coefficients, we demonstrate formally their nonequivalence. Specifically, whereas there are conditions under which α, β, and ω h are equivalent to each other and to one of the two conceptualizations of reliability considered here, we show that equality with this conceptualization of reliability and between α and ω h holds only under a highly restrictive set of conditions and that the conditions under which β equals ω h are only somewhat more general. The nonequivalence of α, β, and ω h suggests that important information about the psychometric properties of a scale may be missing when scale developers and users only report α as is almost always the case},
	language = {en},
	number = {1},
	urldate = {2018-12-20},
	journal = {Psychometrika},
	author = {Zinbarg, Richard E. and Revelle, William and Yovel, Iftah and Li, Wen},
	month = mar,
	year = {2005},
	keywords = {Alternative Conceptualization, Psychometric Property, Public Policy, Statistical Theory, Theoretical Comparison},
	pages = {123--133},
	file = {Springer Full Text PDF:/Users/micl/Zotero/storage/PWZXY6Z2/Zinbarg et al. - 2005 - Cronbach’s α, Revelle’s β, and Mcdonald’s ωH thei.pdf:application/pdf}
}

@article{guttman_basis_1945,
	title = {A basis for analyzing test-retest reliability},
	volume = {10},
	issn = {1860-0980},
	url = {https://doi.org/10.1007/BF02288892},
	doi = {10.1007/BF02288892},
	abstract = {Three sources of variation in experimental results for a test are distinguished: trials, persons, and items. Unreliability is defined only in terms of variation over trials. This definition leads to a more complete analysis than does the conventional one; Spearman's contention is verified that the conventional approach—which was formulated by Yule—introduces unnecessary hypotheses. It is emphasized that at least two trials are necessary to estimate the reliability coefficient. This paper is devoted largely to developinglower bounds to the reliability coefficient that can be computed from but asingle trial; these avoid the experimental difficulties of making two independent trials. Six different lower bounds are established, appropriate for different situations. Some of the bounds are easier to compute than are conventional formulas, and all the bounds assume less than do conventional formulas. The terminology used is that of psychological and sociological testing, but the discussion actually provides a general analysis of the reliability of the sum ofn variables.},
	language = {en},
	number = {4},
	urldate = {2019-01-12},
	journal = {Psychometrika},
	author = {Guttman, Louis},
	month = dec,
	year = {1945},
	keywords = {Conventional Approach, General Analysis, Lower Bound, Public Policy, Statistical Theory},
	pages = {255--282}
}

@article{kelley_confidence_2012,
	title = {Confidence intervals for population reliability coefficients: {Evaluation} of methods, recommendations, and software for composite measures.},
	volume = {8},
	url = {http://psycnet.apa.org/search/display?id=0e8f6328-2a4c-bc07-a8d1-73f18caec397&recordId=1&tab=PA&page=1&display=25&sort=PublicationYearMSSort%20desc,AuthorSort%20asc&sr=1},
	doi = {10.1027/1614-2241/a000036},
	abstract = {The reliability of a composite score is a fundamental and important topic in the social and behavioral sciences. The most commonly used reliability estimate of a composite score is coefficient α. However, under regularity conditions, the population value of coefficient α is only a lower bound on the population reliability, unless the items are essentially τ-equivalent, an assumption that is likely violated in most applications. A generalization of coefficient α, termed ω, is discussed and generally recommended. Furthermore, a point estimate itself almost certainly differs from the population value. Therefore, it is important to provide confidence interval limits so as not to overinterpret the point estimate. Analytic and bootstrap methods are described in detail for confidence interval construction for ω. We go on to recommend the bias-corrected bootstrap approach for ω and provide open source and freely available R functions via the MBESS package to implement the methods discussed.},
	number = {2},
	journal = {Methodology: European Journal of Research Methods for the Behavioral and Social Sciences},
	author = {Kelley, Ken and Chen, Ying},
	year = {2012},
	keywords = {*Confidence Limits (Statistics), *Measurement, *Methodology, *Statistical Reliability, *Test Scores, Computer Software, Statistical Correlation},
	pages = {39--50}
}

@article{terry_sample_2012,
	title = {Sample size planning for composite reliability coefficients: {Accuracy} in parameter estimation via narrow confidence intervals},
	volume = {65},
	copyright = {©2011 The British Psychological Society},
	issn = {2044-8317},
	shorttitle = {Sample size planning for composite reliability coefficients},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8317.2011.02030.x},
	doi = {10.1111/j.2044-8317.2011.02030.x},
	abstract = {Composite measures play an important role in psychology and related disciplines. Composite measures almost always have error. Correspondingly, it is important to understand the reliability of the scores from any particular composite measure. However, the point estimates of the reliability of composite measures are fallible and thus all such point estimates should be accompanied by a confidence interval. When confidence intervals are wide, there is much uncertainty in the population value of the reliability coefficient. Given the importance of reporting confidence intervals for estimates of reliability, coupled with the undesirability of wide confidence intervals, we develop methods that allow researchers to plan sample size in order to obtain narrow confidence intervals for population reliability coefficients. We first discuss composite reliability coefficients and then provide a discussion on confidence interval formation for the corresponding population value. Using the accuracy in parameter estimation approach, we develop two methods to obtain accurate estimates of reliability by planning sample size. The first method provides a way to plan sample size so that the expected confidence interval width for the population reliability coefficient is sufficiently narrow. The second method ensures that the confidence interval width will be sufficiently narrow with some desired degree of assurance (e.g., 99\% assurance that the 95\% confidence interval for the population reliability coefficient will be less than W units wide). The effectiveness of our methods was verified with Monte Carlo simulation studies. We demonstrate how to easily implement the methods with easy-to-use and freely available software.},
	language = {en},
	number = {3},
	urldate = {2018-12-26},
	journal = {British Journal of Mathematical and Statistical Psychology},
	author = {Terry, Leann and Kelley, Ken},
	year = {2012},
	pages = {371--401},
	file = {Snapshot:/Users/micl/Zotero/storage/W5SZLDY6/j.2044-8317.2011.02030.html:text/html}
}

@misc{noauthor_coefficient_nodate,
	title = {Coefficient alpha and the internal structure of tests {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1007/BF02310555},
	urldate = {2019-01-12},
	file = {Coefficient alpha and the internal structure of tests | SpringerLink:/Users/micl/Zotero/storage/S5EHS7MZ/BF02310555.html:text/html}
}

@misc{cronbach_coefficient_nodate,
	title = {Coefficient alpha and the internal structure of tests {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1007/BF02310555},
	urldate = {2019-01-12},
	author = {Cronbach, Lee},
	file = {Coefficient alpha and the internal structure of tests | SpringerLink:/Users/micl/Zotero/storage/UE7RWJXI/BF02310555.html:text/html}
}

@article{cronbach_my_2004,
	title = {My {Current} {Thoughts} on {Coefficient} {Alpha} and {Successor} {Procedures}},
	volume = {64},
	issn = {0013-1644},
	url = {https://doi.org/10.1177/0013164404266386},
	doi = {10.1177/0013164404266386},
	abstract = {In 1997, noting that the 50th anniversary of the publication of “Coefficient Alpha and the Internal Structure of Tests” was fast approaching, Lee Cronbach planned what have become the notes published here. His aimwas to point out theways in which his views on coefficient alpha had evolved, doubting nowthat the coefficientwas the bestway of judging the reliability of an instrument to which it was applied. Tracing in these notes, in vintage Cronbach style, his thinking before, during, and after the publication of the alpha paper, his “current thoughts” on coefficient alpha are that alpha covers only a small perspective of the range of measurement uses for which reliability information is needed and that it should be viewed within a much larger system of reliability analysis, generalizability theory.},
	language = {en},
	number = {3},
	urldate = {2019-01-12},
	journal = {Educational and Psychological Measurement},
	author = {Cronbach, Lee J. and Shavelson, Richard J.},
	month = jun,
	year = {2004},
	pages = {391--418}
}
</script>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
